{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuEQDZGmi6PexfJbdYfQEZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericyoc/malicious_js_id_proc/blob/main/malicious_js_id_poc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install numpy pandas scikit-learn tensorflow matplotlib prettytable"
      ],
      "metadata": {
        "id": "Etbwj7imngbx"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bz4VykWFQVpI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "from prettytable import PrettyTable\n",
        "import random\n",
        "import string\n",
        "import os\n",
        "from scipy import stats"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the content directory\n",
        "content_dir = '/content'"
      ],
      "metadata": {
        "id": "O39uLI_s4M6v"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_category_data(category_file):\n",
        "    print(\"Loading category data...\")\n",
        "    category_df = pd.read_csv(category_file)\n",
        "    print(f\"Category file columns: {category_df.columns}\")\n",
        "\n",
        "    X = []\n",
        "    y = []\n",
        "    for i, (_, row) in enumerate(category_df.iterrows()):\n",
        "        features = extract_advanced_features(row)\n",
        "        X.append(features)\n",
        "        y.append(1 if row['category'] == 'worm' else 0)\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Processing sample {i}/{len(category_df)}\", end=\"\\r\")\n",
        "\n",
        "    print(\"Data loading complete.\")\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "f2r9Dx7C36gf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_metadata_data(metadata_file):\n",
        "    print(\"Loading metadata data...\")\n",
        "    metadata_df = pd.read_csv(metadata_file)\n",
        "    print(f\"Metadata file columns: {metadata_df.columns}\")\n",
        "\n",
        "    X = []\n",
        "    for i, (_, row) in enumerate(metadata_df.iterrows()):\n",
        "        features = extract_advanced_features(row)\n",
        "        X.append(features)\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Processing sample {i}/{len(metadata_df)}\", end=\"\\r\")\n",
        "\n",
        "    print(\"Data loading complete.\")\n",
        "    return np.array(X)"
      ],
      "metadata": {
        "id": "gp0UAvDT4RXt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_advanced_features(row):\n",
        "    features = {\n",
        "        'sha_length': len(str(row.get('sha256', row.get('sha', '')))),\n",
        "        'category_length': len(str(row.get('category', ''))),\n",
        "        'timestamp_length': len(str(row.get('timestamp', ''))),\n",
        "        'family_length': len(str(row.get('family', ''))),\n",
        "        'num_unique_chars': len(set(str(row))),\n",
        "        'total_string_length': len(str(row))\n",
        "    }\n",
        "    return list(features.values())"
      ],
      "metadata": {
        "id": "Rx8uCdDf9Rl3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_obfuscation(data, obfuscation_level):\n",
        "    if obfuscation_level == 'low':\n",
        "        noise = np.random.normal(0, 0.1, data.shape).astype(data.dtype)\n",
        "        return data.astype(np.float64) + noise\n",
        "    elif obfuscation_level == 'medium':\n",
        "        X_obf = []\n",
        "        for row in data:\n",
        "            obfuscated_row = []\n",
        "            for feature in row:\n",
        "                if isinstance(feature, str):\n",
        "                    new_feature = ''.join(random.choices(string.ascii_letters + string.digits, k=int(feature * 1.5)))\n",
        "                else:\n",
        "                    new_feature = feature\n",
        "                obfuscated_row.append(new_feature)\n",
        "            X_obf.append(obfuscated_row)\n",
        "        return np.array(X_obf, dtype=object)\n",
        "    elif obfuscation_level == 'high':\n",
        "        return data[:, np.random.permutation(data.shape[1])]\n",
        "    else:\n",
        "        return data"
      ],
      "metadata": {
        "id": "yel_J1C64VLR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def deobfuscate_data(X, obfuscation_level):\n",
        "    if obfuscation_level == 'none':\n",
        "        return X\n",
        "    elif obfuscation_level == 'low':\n",
        "        return X  # No real deobfuscation for low level\n",
        "    elif obfuscation_level == 'medium':\n",
        "        return X  # No real deobfuscation for medium level\n",
        "    elif obfuscation_level == 'high':\n",
        "        return X[:, np.argsort(range(X.shape[1]))]  # Attempt to reverse the column shuffle\n",
        "    return X"
      ],
      "metadata": {
        "id": "XacUEFrE4XFH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(X, y=None, obfuscation_level='none'):\n",
        "    print(f\"Preprocessing data with obfuscation level: {obfuscation_level}\")\n",
        "    X_obf = apply_obfuscation(X, obfuscation_level)\n",
        "    X_deobf = deobfuscate_data(X_obf, obfuscation_level)\n",
        "    if y is not None:\n",
        "        return X_obf, X_deobf, y\n",
        "    else:\n",
        "        return X_obf, X_deobf"
      ],
      "metadata": {
        "id": "2loxiGms4ZPs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(input_dim, layers=[64, 32], learning_rate=0.001):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(input_dim,)))\n",
        "    model.add(Dense(layers[0], activation='relu'))\n",
        "    for layer_size in layers[1:]:\n",
        "        model.add(Dense(layer_size, activation='relu'))\n",
        "        model.add(Dropout(0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "JxlR1QpJ4erX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_hyperparameters(X, y):\n",
        "    best_params = {}\n",
        "    best_score = 0\n",
        "\n",
        "    layers = [[64, 32], [128, 64], [256, 128, 64]]\n",
        "    learning_rates = [0.001, 0.01]\n",
        "    epochs = [10]\n",
        "    batch_sizes = [32, 64]\n",
        "\n",
        "    total_combinations = len(layers) * len(learning_rates) * len(epochs) * len(batch_sizes)\n",
        "    combination_count = 0\n",
        "\n",
        "    for layer_config in layers:\n",
        "        for lr in learning_rates:\n",
        "            for epoch in epochs:\n",
        "                for batch_size in batch_sizes:\n",
        "                    combination_count += 1\n",
        "                    print(f\"Testing configuration {combination_count}/{total_combinations}: layers={layer_config}, learning_rate={lr}, epochs={epoch}, batch_size={batch_size}\")\n",
        "                    model = create_model(input_dim=X.shape[1], layers=layer_config, learning_rate=lr)\n",
        "\n",
        "                    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "                    history = model.fit(X_train, y_train, epochs=epoch, batch_size=batch_size, validation_data=(X_val, y_val), verbose=1)\n",
        "                    val_accuracy = history.history['val_accuracy'][-1]\n",
        "\n",
        "                    if val_accuracy > best_score:\n",
        "                        best_score = val_accuracy\n",
        "                        best_params = {\n",
        "                            'layers': layer_config,\n",
        "                            'learning_rate': lr,\n",
        "                            'epochs': epoch,\n",
        "                            'batch_size': batch_size\n",
        "                        }\n",
        "\n",
        "    return best_params"
      ],
      "metadata": {
        "id": "xl0qFsQc4gcd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_results(results_dict, title, filename):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    for level, data in results_dict.items():\n",
        "        plt.plot(data['obfuscated']['history'].history['accuracy'], label=f\"Obfuscated - {level}\")\n",
        "        plt.plot(data['deobfuscated']['history'].history['accuracy'], label=f\"Deobfuscated - {level}\")\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    full_path = os.path.join(content_dir, filename)\n",
        "    plt.savefig(full_path)\n",
        "    plt.close()\n",
        "    print(f\"Plot saved to {full_path}\")"
      ],
      "metadata": {
        "id": "PAodXNHl4jTL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model, filename):\n",
        "    full_path = os.path.join(content_dir, filename)\n",
        "    model.save(full_path, save_format='keras')\n",
        "    print(f\"Model saved to {full_path}\")"
      ],
      "metadata": {
        "id": "jJH9mSV94lQ-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_metrics(metrics, filename):\n",
        "    full_path = os.path.join(content_dir, filename)\n",
        "    with open(full_path, 'w') as f:\n",
        "        for metric_name, metric_value in metrics.items():\n",
        "            f.write(f\"{metric_name}: {metric_value}\\n\")\n",
        "    print(f\"Metrics saved to {full_path}\")"
      ],
      "metadata": {
        "id": "4C-6YBxO4nhi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "\n",
        "    accuracy = model.evaluate(X_test, y_test)[1]\n",
        "    roc_auc = roc_auc_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred_binary)\n",
        "    recall = recall_score(y_test, y_pred_binary)\n",
        "    f1 = f1_score(y_test, y_pred_binary)\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'roc_auc': roc_auc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }"
      ],
      "metadata": {
        "id": "fW-880c64pOW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KerasClassifierWrapper(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, build_fn, **kwargs):\n",
        "        self.build_fn = build_fn\n",
        "        self.kwargs = kwargs\n",
        "        self.model = None\n",
        "\n",
        "    def fit(self, X, y, **kwargs):\n",
        "        if self.model is None:\n",
        "            self.model = self.build_fn()\n",
        "        self.model.fit(X, y, **kwargs)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return (self.model.predict(X) > 0.5).astype(int)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        proba = self.model.predict(X)\n",
        "        return np.column_stack([1 - proba, proba])\n",
        "\n",
        "    def get_params(self, deep=True):\n",
        "        return {'build_fn': self.build_fn, **self.kwargs}\n",
        "\n",
        "    def set_params(self, **params):\n",
        "        self.kwargs.update(params)\n",
        "        return self"
      ],
      "metadata": {
        "id": "O3wEqzutGPdU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def cross_validate_model(X, y, model_builder, cv=5):\n",
        "    keras_classifier = KerasClassifierWrapper(build_fn=model_builder)\n",
        "    cv_scores = cross_val_score(keras_classifier, X, y, cv=cv, scoring='accuracy')\n",
        "    return cv_scores.mean(), cv_scores.std()"
      ],
      "metadata": {
        "id": "il7yUZyN6Py2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model_wrapper(input_dim, layers, learning_rate):\n",
        "    def model_builder():\n",
        "        return create_model(input_dim, layers, learning_rate)\n",
        "    return model_builder"
      ],
      "metadata": {
        "id": "LPTtIYBTGWd7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def statistical_significance_test(results):\n",
        "    obfuscation_levels = list(results.keys())\n",
        "    obfuscated_accuracies = [results[level]['obfuscated']['metrics']['accuracy'] for level in obfuscation_levels]\n",
        "    deobfuscated_accuracies = [results[level]['deobfuscated']['metrics']['accuracy'] for level in obfuscation_levels]\n",
        "\n",
        "    f_statistic, p_value = stats.f_oneway(obfuscated_accuracies, deobfuscated_accuracies)\n",
        "    return f_statistic, p_value"
      ],
      "metadata": {
        "id": "a6noiKTk6Rad"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    category_file = 'bodmas_malware_category.csv'\n",
        "    metadata_file = 'bodmas_metadata.csv'\n",
        "\n",
        "    # Load category data\n",
        "    X_category, y_category = load_category_data(category_file)\n",
        "\n",
        "    # Load metadata data\n",
        "    X_metadata = load_metadata_data(metadata_file)\n",
        "\n",
        "    print(f\"Shape of X_category: {X_category.shape}\")\n",
        "    print(f\"Shape of X_metadata: {X_metadata.shape}\")\n",
        "\n",
        "    # Ensure X_category and X_metadata have the same number of samples\n",
        "    if X_category.shape[0] != X_metadata.shape[0]:\n",
        "        min_samples = min(X_category.shape[0], X_metadata.shape[0])\n",
        "        X_category = X_category[:min_samples]\n",
        "        X_metadata = X_metadata[:min_samples]\n",
        "        y_category = y_category[:min_samples]\n",
        "        print(f\"Adjusted shapes to {min_samples} samples\")\n",
        "\n",
        "    # Concatenate the category and metadata features\n",
        "    X = np.hstack([X_category, X_metadata])\n",
        "\n",
        "    obfuscation_levels = ['none', 'low', 'medium', 'high']\n",
        "    results = {}\n",
        "\n",
        "    for level in obfuscation_levels:\n",
        "        print(f\"\\nProcessing obfuscation level: {level}\")\n",
        "        X_obf, X_deobf, y_obf = preprocess_data(X, y_category, level)\n",
        "\n",
        "        results[level] = {'obfuscated': {}, 'deobfuscated': {}}\n",
        "\n",
        "        for data_type, X_processed in [('obfuscated', X_obf), ('deobfuscated', X_deobf)]:\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X_processed, y_obf, test_size=0.2, random_state=42)\n",
        "\n",
        "            scaler = StandardScaler()\n",
        "            X_train_scaled = scaler.fit_transform(X_train)\n",
        "            X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "            print(f\"Optimizing hyperparameters for {data_type} data...\")\n",
        "            best_params = optimize_hyperparameters(X_train_scaled, y_train)\n",
        "\n",
        "            print(f\"Best parameters for {data_type}: {best_params}\")\n",
        "\n",
        "            model_builder = create_model_wrapper(input_dim=X_train_scaled.shape[1],\n",
        "                                                 layers=best_params['layers'],\n",
        "                                                 learning_rate=best_params['learning_rate'])\n",
        "\n",
        "            # Perform cross-validation\n",
        "            cv_mean, cv_std = cross_validate_model(X_train_scaled, y_train, model_builder)\n",
        "            print(f\"Cross-validation accuracy for {data_type}: {cv_mean:.4f} (+/- {cv_std:.4f})\")\n",
        "\n",
        "            print(f\"Training model on {data_type} data...\")\n",
        "            model = create_model(input_dim=X_train_scaled.shape[1],\n",
        "                                 layers=best_params['layers'],\n",
        "                                 learning_rate=best_params['learning_rate'])\n",
        "\n",
        "            history = model.fit(X_train_scaled, y_train,\n",
        "                                epochs=best_params['epochs'],\n",
        "                                batch_size=best_params['batch_size'],\n",
        "                                validation_split=0.2,\n",
        "                                verbose=1)\n",
        "\n",
        "            metrics = evaluate_model(model, X_test_scaled, y_test)\n",
        "            results[level][data_type] = {'metrics': metrics, 'history': history}\n",
        "\n",
        "            save_model(model, f'model_{level}_{data_type}.keras')\n",
        "            save_metrics(metrics, f'metrics_{level}_{data_type}.txt')\n",
        "\n",
        "    # Perform statistical significance test\n",
        "    f_statistic, p_value = statistical_significance_test(results)\n",
        "    print(f\"\\nStatistical Significance Test:\")\n",
        "    print(f\"F-statistic: {f_statistic}\")\n",
        "    print(f\"p-value: {p_value}\")\n",
        "\n",
        "    # Plot results\n",
        "    plot_results(results, \"Model Performance Across Obfuscation Levels\", \"performance_plot.png\")\n",
        "\n",
        "    # Summary table\n",
        "    table = PrettyTable()\n",
        "    table.field_names = [\"Obfuscation Level\", \"Data Type\", \"Accuracy\", \"ROC AUC\", \"Precision\", \"Recall\", \"F1 Score\"]\n",
        "    for level, data in results.items():\n",
        "        for data_type in ['obfuscated', 'deobfuscated']:\n",
        "            metrics = data[data_type]['metrics']\n",
        "            table.add_row([\n",
        "                level,\n",
        "                data_type,\n",
        "                f\"{metrics['accuracy']:.4f}\",\n",
        "                f\"{metrics['roc_auc']:.4f}\",\n",
        "                f\"{metrics['precision']:.4f}\",\n",
        "                f\"{metrics['recall']:.4f}\",\n",
        "                f\"{metrics['f1']:.4f}\"\n",
        "            ])\n",
        "    print(\"\\nPerformance Summary:\")\n",
        "    print(table)\n",
        "\n",
        "    # Save the summary table\n",
        "    table_str = table.get_string()\n",
        "    with open(os.path.join(content_dir, 'summary_table.txt'), 'w') as f:\n",
        "        f.write(table_str)\n",
        "    print(f\"Summary table saved to {os.path.join(content_dir, 'summary_table.txt')}\")"
      ],
      "metadata": {
        "id": "yDDDSzFd4s7H"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4d-QoHC4ztA",
        "outputId": "bf8c8e2f-2216-4d44-c8b6-556089224e32"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading category data...\n",
            "Category file columns: Index(['sha256', 'category'], dtype='object')\n",
            "Data loading complete.\n",
            "Loading metadata data...\n",
            "Metadata file columns: Index(['sha', 'timestamp', 'family'], dtype='object')\n",
            "Data loading complete.\n",
            "Shape of X_category: (57293, 6)\n",
            "Shape of X_metadata: (134435, 6)\n",
            "Adjusted shapes to 57293 samples\n",
            "\n",
            "Processing obfuscation level: none\n",
            "Preprocessing data with obfuscation level: none\n",
            "Optimizing hyperparameters for obfuscated data...\n",
            "Testing configuration 1/12: layers=[64, 32], learning_rate=0.001, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9478 - loss: 0.1594 - val_accuracy: 0.9992 - val_loss: 0.0123\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0076 - val_accuracy: 0.9992 - val_loss: 0.0131\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0070 - val_accuracy: 0.9992 - val_loss: 0.0148\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0045 - val_accuracy: 0.9992 - val_loss: 0.0164\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0034 - val_accuracy: 0.9992 - val_loss: 0.0156\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0035 - val_accuracy: 0.9992 - val_loss: 0.0173\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0033 - val_accuracy: 0.9992 - val_loss: 0.0179\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0022 - val_accuracy: 0.9992 - val_loss: 0.0174\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0031 - val_accuracy: 0.9992 - val_loss: 0.0205\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 7.8590e-04 - val_accuracy: 0.9992 - val_loss: 0.0200\n",
            "Testing configuration 2/12: layers=[64, 32], learning_rate=0.001, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9294 - loss: 0.2270 - val_accuracy: 0.9992 - val_loss: 0.0079\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0068 - val_accuracy: 0.9992 - val_loss: 0.0119\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0058 - val_accuracy: 0.9992 - val_loss: 0.0123\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0064 - val_accuracy: 0.9992 - val_loss: 0.0128\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0054 - val_accuracy: 0.9992 - val_loss: 0.0132\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0045 - val_accuracy: 0.9992 - val_loss: 0.0123\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0041 - val_accuracy: 0.9992 - val_loss: 0.0131\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0038 - val_accuracy: 0.9992 - val_loss: 0.0131\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0048 - val_accuracy: 0.9992 - val_loss: 0.0133\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0040 - val_accuracy: 0.9992 - val_loss: 0.0120\n",
            "Testing configuration 3/12: layers=[64, 32], learning_rate=0.01, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9838 - loss: 0.0402 - val_accuracy: 0.9992 - val_loss: 0.1255\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0055 - val_accuracy: 0.9992 - val_loss: 0.1153\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0043 - val_accuracy: 0.9992 - val_loss: 0.0846\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0020 - val_accuracy: 0.9992 - val_loss: 0.0936\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0023 - val_accuracy: 0.9992 - val_loss: 0.0641\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 8.2234e-04 - val_accuracy: 0.9990 - val_loss: 0.0737\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0035 - val_accuracy: 0.9996 - val_loss: 0.0624\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0048 - val_accuracy: 0.9992 - val_loss: 0.1449\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0015 - val_accuracy: 0.9992 - val_loss: 0.0713\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 4.6351e-04 - val_accuracy: 0.9996 - val_loss: 0.0527\n",
            "Testing configuration 4/12: layers=[64, 32], learning_rate=0.01, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9743 - loss: 0.0577 - val_accuracy: 0.9991 - val_loss: 0.0497\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0077 - val_accuracy: 0.9992 - val_loss: 0.0544\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0064 - val_accuracy: 0.9992 - val_loss: 0.0219\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0042 - val_accuracy: 0.9992 - val_loss: 0.0160\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0033 - val_accuracy: 0.9992 - val_loss: 0.2417\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0019 - val_accuracy: 0.9992 - val_loss: 0.2426\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0011 - val_accuracy: 0.9992 - val_loss: 0.2529\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 7.2508e-04 - val_accuracy: 0.9998 - val_loss: 0.2599\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.0075e-04 - val_accuracy: 0.9998 - val_loss: 0.2600\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7061e-04 - val_accuracy: 0.9998 - val_loss: 0.2595\n",
            "Testing configuration 5/12: layers=[128, 64], learning_rate=0.001, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9632 - loss: 0.1182 - val_accuracy: 0.9992 - val_loss: 0.0188\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0067 - val_accuracy: 0.9992 - val_loss: 0.0192\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0055 - val_accuracy: 0.9992 - val_loss: 0.0200\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0042 - val_accuracy: 0.9992 - val_loss: 0.0211\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0026 - val_accuracy: 0.9992 - val_loss: 0.0194\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.9996 - val_loss: 0.0204\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 2.9693e-04 - val_accuracy: 0.9998 - val_loss: 0.0214\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 2.3917e-04 - val_accuracy: 0.9997 - val_loss: 0.0219\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1007e-04 - val_accuracy: 0.9998 - val_loss: 0.0203\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.2051e-05 - val_accuracy: 0.9998 - val_loss: 0.0212\n",
            "Testing configuration 6/12: layers=[128, 64], learning_rate=0.001, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9567 - loss: 0.1599 - val_accuracy: 0.9992 - val_loss: 0.0196\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0069 - val_accuracy: 0.9992 - val_loss: 0.0216\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0056 - val_accuracy: 0.9992 - val_loss: 0.0219\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0050 - val_accuracy: 0.9992 - val_loss: 0.0235\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0040 - val_accuracy: 0.9992 - val_loss: 0.0247\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0058 - val_accuracy: 0.9992 - val_loss: 0.0249\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0033 - val_accuracy: 0.9992 - val_loss: 0.0255\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0035 - val_accuracy: 0.9992 - val_loss: 0.0271\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0022 - val_accuracy: 0.9993 - val_loss: 0.0276\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 7.8110e-04 - val_accuracy: 0.9997 - val_loss: 0.0294\n",
            "Testing configuration 7/12: layers=[128, 64], learning_rate=0.01, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9912 - loss: 0.0312 - val_accuracy: 0.9991 - val_loss: 0.0913\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0059 - val_accuracy: 0.9992 - val_loss: 0.0855\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0082 - val_accuracy: 0.9992 - val_loss: 0.1145\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0029 - val_accuracy: 0.9992 - val_loss: 0.1189\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0020 - val_accuracy: 0.9992 - val_loss: 0.1130\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 7.7949e-04 - val_accuracy: 0.9992 - val_loss: 0.0841\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0010 - val_accuracy: 0.9992 - val_loss: 0.0715\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 2.7966e-04 - val_accuracy: 0.9998 - val_loss: 0.0726\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 6.7579e-04 - val_accuracy: 0.9998 - val_loss: 0.0552\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8756e-04 - val_accuracy: 0.9998 - val_loss: 0.0405\n",
            "Testing configuration 8/12: layers=[128, 64], learning_rate=0.01, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9829 - loss: 0.0402 - val_accuracy: 0.9992 - val_loss: 0.2866\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0067 - val_accuracy: 0.9992 - val_loss: 0.3064\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0043 - val_accuracy: 0.9975 - val_loss: 0.3461\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0100 - val_accuracy: 0.9992 - val_loss: 0.2726\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0046 - val_accuracy: 0.9992 - val_loss: 0.2838\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0040 - val_accuracy: 0.9996 - val_loss: 0.2270\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 8.1535e-04 - val_accuracy: 0.9998 - val_loss: 0.2073\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 9.7498e-05 - val_accuracy: 0.9998 - val_loss: 0.2041\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 2.2861e-04 - val_accuracy: 0.9995 - val_loss: 0.1620\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 2.2443e-04 - val_accuracy: 0.9995 - val_loss: 0.1518\n",
            "Testing configuration 9/12: layers=[256, 128, 64], learning_rate=0.001, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9785 - loss: 0.0689 - val_accuracy: 0.9992 - val_loss: 0.0501\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0056 - val_accuracy: 0.9992 - val_loss: 0.0520\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0036 - val_accuracy: 0.9992 - val_loss: 0.0459\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0022 - val_accuracy: 0.9992 - val_loss: 0.0404\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0012 - val_accuracy: 0.9998 - val_loss: 0.0346\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 4.7985e-04 - val_accuracy: 0.9998 - val_loss: 0.0291\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.0139e-05 - val_accuracy: 0.9998 - val_loss: 0.0396\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 2.7423e-04 - val_accuracy: 0.9996 - val_loss: 0.0176\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 3.0492e-04 - val_accuracy: 0.9998 - val_loss: 0.0148\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.4117e-05 - val_accuracy: 0.9996 - val_loss: 0.0513\n",
            "Testing configuration 10/12: layers=[256, 128, 64], learning_rate=0.001, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9746 - loss: 0.0924 - val_accuracy: 0.9992 - val_loss: 0.0148\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0045 - val_accuracy: 0.9992 - val_loss: 0.0074\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0068 - val_accuracy: 0.9992 - val_loss: 0.0061\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9993 - loss: 0.0046 - val_accuracy: 0.9992 - val_loss: 0.0831\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0025 - val_accuracy: 0.9992 - val_loss: 0.0835\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 7.2379e-04 - val_accuracy: 0.9992 - val_loss: 0.0915\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 4.4491e-04 - val_accuracy: 0.9998 - val_loss: 0.0985\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.3165e-04 - val_accuracy: 0.9998 - val_loss: 0.1009\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.4660e-05 - val_accuracy: 0.9998 - val_loss: 0.1043\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.8392e-05 - val_accuracy: 0.9998 - val_loss: 0.1021\n",
            "Testing configuration 11/12: layers=[256, 128, 64], learning_rate=0.01, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9913 - loss: 0.0388 - val_accuracy: 0.9992 - val_loss: 0.3692\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0189 - val_accuracy: 0.9992 - val_loss: 0.7826\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0079 - val_accuracy: 0.9992 - val_loss: 0.7780\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0106 - val_accuracy: 0.9992 - val_loss: 0.5263\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0044 - val_accuracy: 0.9991 - val_loss: 0.6174\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0038 - val_accuracy: 0.9991 - val_loss: 0.5539\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0029 - val_accuracy: 0.9992 - val_loss: 0.4523\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0041 - val_accuracy: 0.9992 - val_loss: 1.7160\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0116 - val_accuracy: 0.9988 - val_loss: 0.2823\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0209 - val_accuracy: 0.9992 - val_loss: 0.7625\n",
            "Testing configuration 12/12: layers=[256, 128, 64], learning_rate=0.01, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9852 - loss: 0.0387 - val_accuracy: 0.9989 - val_loss: 1.0292\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9996 - loss: 0.0048 - val_accuracy: 0.9992 - val_loss: 1.6093\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0028 - val_accuracy: 0.9996 - val_loss: 1.7488\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0067 - val_accuracy: 0.9992 - val_loss: 2.2229\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0095 - val_accuracy: 0.9990 - val_loss: 1.1981\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0080 - val_accuracy: 0.9992 - val_loss: 1.1885\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0037 - val_accuracy: 0.9992 - val_loss: 1.3234\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0030 - val_accuracy: 0.9992 - val_loss: 1.3107\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0034 - val_accuracy: 0.9992 - val_loss: 2.5880\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0057 - val_accuracy: 0.9992 - val_loss: 2.4886\n",
            "Best parameters for obfuscated: {'layers': [64, 32], 'learning_rate': 0.01, 'epochs': 10, 'batch_size': 64}\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9894 - loss: 0.0468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:839: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
            "    score = scorer._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_response.py\", line 182, in _get_response_values\n",
            "    classes = estimator.classes_\n",
            "AttributeError: 'KerasClassifierWrapper' object has no attribute 'classes_'\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9907 - loss: 0.0493\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9863 - loss: 0.0466\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0391\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9912 - loss: 0.0524\n",
            "Cross-validation accuracy for obfuscated: nan (+/- nan)\n",
            "Training model on obfuscated data...\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9784 - loss: 0.0664 - val_accuracy: 0.9993 - val_loss: 0.0057\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0055 - val_accuracy: 0.9993 - val_loss: 0.0045\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0044 - val_accuracy: 0.9993 - val_loss: 0.0025\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0041 - val_accuracy: 0.9993 - val_loss: 0.0022\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0016 - val_accuracy: 0.9993 - val_loss: 8.6822e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 6.2532e-04 - val_accuracy: 0.9999 - val_loss: 5.1700e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6013e-04 - val_accuracy: 0.9993 - val_loss: 0.0016\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 2.9613e-04 - val_accuracy: 0.9999 - val_loss: 5.7945e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1716e-04 - val_accuracy: 0.9999 - val_loss: 4.2900e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.5538e-04 - val_accuracy: 1.0000 - val_loss: 1.8384e-04\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6821e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/model_none_obfuscated.keras\n",
            "Metrics saved to /content/metrics_none_obfuscated.txt\n",
            "Optimizing hyperparameters for deobfuscated data...\n",
            "Testing configuration 1/12: layers=[64, 32], learning_rate=0.001, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9449 - loss: 0.1660 - val_accuracy: 0.9992 - val_loss: 0.0240\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0055 - val_accuracy: 0.9992 - val_loss: 0.0262\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0036 - val_accuracy: 0.9992 - val_loss: 0.0308\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0043 - val_accuracy: 0.9992 - val_loss: 0.0347\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0062 - val_accuracy: 0.9992 - val_loss: 0.0369\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0031 - val_accuracy: 0.9992 - val_loss: 0.0386\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0033 - val_accuracy: 0.9992 - val_loss: 0.0395\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0037 - val_accuracy: 0.9992 - val_loss: 0.0392\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0020 - val_accuracy: 0.9992 - val_loss: 0.0385\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0011 - val_accuracy: 0.9992 - val_loss: 0.0430\n",
            "Testing configuration 2/12: layers=[64, 32], learning_rate=0.001, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9343 - loss: 0.2249 - val_accuracy: 0.9992 - val_loss: 0.0107\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0066 - val_accuracy: 0.9992 - val_loss: 0.0105\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0044 - val_accuracy: 0.9992 - val_loss: 0.0106\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0051 - val_accuracy: 0.9992 - val_loss: 0.0115\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0049 - val_accuracy: 0.9992 - val_loss: 0.0106\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0051 - val_accuracy: 0.9992 - val_loss: 0.0114\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0029 - val_accuracy: 0.9992 - val_loss: 0.0111\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0042 - val_accuracy: 0.9992 - val_loss: 0.0116\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0027 - val_accuracy: 0.9992 - val_loss: 0.0112\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0032 - val_accuracy: 0.9992 - val_loss: 0.0111\n",
            "Testing configuration 3/12: layers=[64, 32], learning_rate=0.01, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9884 - loss: 0.0361 - val_accuracy: 0.9992 - val_loss: 0.0380\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0084 - val_accuracy: 0.9991 - val_loss: 0.0432\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0030 - val_accuracy: 0.9992 - val_loss: 0.0465\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0023 - val_accuracy: 0.9992 - val_loss: 0.0209\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0026 - val_accuracy: 0.9992 - val_loss: 0.0290\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.9992 - val_loss: 0.0295\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 8.6975e-04 - val_accuracy: 0.9992 - val_loss: 0.0099\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0022 - val_accuracy: 0.9992 - val_loss: 0.0585\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0022 - val_accuracy: 0.9992 - val_loss: 0.0747\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0016 - val_accuracy: 0.9996 - val_loss: 0.0583\n",
            "Testing configuration 4/12: layers=[64, 32], learning_rate=0.01, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9710 - loss: 0.0685 - val_accuracy: 0.9993 - val_loss: 0.0117\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0073 - val_accuracy: 0.9992 - val_loss: 0.0312\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0052 - val_accuracy: 0.9992 - val_loss: 0.0464\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0035 - val_accuracy: 0.9992 - val_loss: 0.0260\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0018 - val_accuracy: 0.9992 - val_loss: 0.0180\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0015 - val_accuracy: 0.9992 - val_loss: 0.0153\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 5.6076e-04 - val_accuracy: 0.9992 - val_loss: 0.0144\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 5.2756e-04 - val_accuracy: 0.9966 - val_loss: 0.0550\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0057 - val_accuracy: 0.9992 - val_loss: 0.6044\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0016 - val_accuracy: 0.9992 - val_loss: 0.5984\n",
            "Testing configuration 5/12: layers=[128, 64], learning_rate=0.001, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9651 - loss: 0.1003 - val_accuracy: 0.9992 - val_loss: 0.0231\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0080 - val_accuracy: 0.9992 - val_loss: 0.0251\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0047 - val_accuracy: 0.9992 - val_loss: 0.0264\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0035 - val_accuracy: 0.9992 - val_loss: 0.0260\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0037 - val_accuracy: 0.9992 - val_loss: 0.0221\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0034 - val_accuracy: 0.9992 - val_loss: 0.0232\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0015 - val_accuracy: 0.9992 - val_loss: 0.0248\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 8.5471e-04 - val_accuracy: 0.9992 - val_loss: 0.0253\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 2.3125e-04 - val_accuracy: 0.9996 - val_loss: 0.0268\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0151e-04 - val_accuracy: 0.9996 - val_loss: 0.0269\n",
            "Testing configuration 6/12: layers=[128, 64], learning_rate=0.001, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9502 - loss: 0.1542 - val_accuracy: 0.9992 - val_loss: 0.0148\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0053 - val_accuracy: 0.9992 - val_loss: 0.0158\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0053 - val_accuracy: 0.9992 - val_loss: 0.0167\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0049 - val_accuracy: 0.9992 - val_loss: 0.0178\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0045 - val_accuracy: 0.9992 - val_loss: 0.0198\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0045 - val_accuracy: 0.9992 - val_loss: 0.0203\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0040 - val_accuracy: 0.9992 - val_loss: 0.0216\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0021 - val_accuracy: 0.9992 - val_loss: 0.0231\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0016 - val_accuracy: 0.9992 - val_loss: 0.0230\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 9.4075e-04 - val_accuracy: 0.9992 - val_loss: 0.0257\n",
            "Testing configuration 7/12: layers=[128, 64], learning_rate=0.01, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9886 - loss: 0.0383 - val_accuracy: 0.9992 - val_loss: 0.1753\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0043 - val_accuracy: 0.9992 - val_loss: 0.1974\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0039 - val_accuracy: 0.9992 - val_loss: 0.2366\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0032 - val_accuracy: 0.9992 - val_loss: 0.1968\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0022 - val_accuracy: 0.9992 - val_loss: 0.1383\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0023 - val_accuracy: 0.9992 - val_loss: 0.2213\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0011 - val_accuracy: 0.9998 - val_loss: 0.1971\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 9.5914e-04 - val_accuracy: 0.9998 - val_loss: 0.0763\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 2.4741e-04 - val_accuracy: 0.9998 - val_loss: 0.1528\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 1.3706e-04 - val_accuracy: 0.9998 - val_loss: 0.1449\n",
            "Testing configuration 8/12: layers=[128, 64], learning_rate=0.01, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9876 - loss: 0.0383 - val_accuracy: 0.9991 - val_loss: 0.2740\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0069 - val_accuracy: 0.9992 - val_loss: 0.2858\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0050 - val_accuracy: 0.9991 - val_loss: 0.2901\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0049 - val_accuracy: 0.9992 - val_loss: 0.3630\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0026 - val_accuracy: 0.9992 - val_loss: 0.3951\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 8.3072e-04 - val_accuracy: 0.9992 - val_loss: 0.4162\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 3.2780e-04 - val_accuracy: 0.9997 - val_loss: 0.4100\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 4.0727e-04 - val_accuracy: 0.9991 - val_loss: 0.6698\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0136 - val_accuracy: 0.9991 - val_loss: 0.4921\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0029 - val_accuracy: 0.9991 - val_loss: 0.4632\n",
            "Testing configuration 9/12: layers=[256, 128, 64], learning_rate=0.001, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9779 - loss: 0.0733 - val_accuracy: 0.9992 - val_loss: 0.0279\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0064 - val_accuracy: 0.9992 - val_loss: 0.0305\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0046 - val_accuracy: 0.9992 - val_loss: 0.0175\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0024 - val_accuracy: 0.9992 - val_loss: 0.0200\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0012 - val_accuracy: 0.9997 - val_loss: 0.0115\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.2033e-04 - val_accuracy: 0.9998 - val_loss: 0.0070\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.0999e-04 - val_accuracy: 0.9998 - val_loss: 0.0136\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.2563e-05 - val_accuracy: 0.9998 - val_loss: 0.0214\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0010 - val_accuracy: 0.9998 - val_loss: 0.0063\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 3.4707e-04 - val_accuracy: 0.9998 - val_loss: 0.3706\n",
            "Testing configuration 10/12: layers=[256, 128, 64], learning_rate=0.001, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9692 - loss: 0.0929 - val_accuracy: 0.9991 - val_loss: 0.0224\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0047 - val_accuracy: 0.9992 - val_loss: 0.0249\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0037 - val_accuracy: 0.9992 - val_loss: 0.0174\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0026 - val_accuracy: 0.9992 - val_loss: 0.0127\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0013 - val_accuracy: 0.9996 - val_loss: 0.0065\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 2.7656e-04 - val_accuracy: 0.9996 - val_loss: 0.0092\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 2.1134e-04 - val_accuracy: 0.9998 - val_loss: 0.0078\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.5986e-04 - val_accuracy: 0.9998 - val_loss: 0.0077\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.1878e-05 - val_accuracy: 0.9993 - val_loss: 0.0124\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9994 - loss: 0.0080 - val_accuracy: 0.9998 - val_loss: 0.1641\n",
            "Testing configuration 11/12: layers=[256, 128, 64], learning_rate=0.01, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9897 - loss: 0.0491 - val_accuracy: 0.9991 - val_loss: 0.4493\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0091 - val_accuracy: 0.9991 - val_loss: 0.4814\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0048 - val_accuracy: 0.9991 - val_loss: 0.5066\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0050 - val_accuracy: 0.9988 - val_loss: 1.1099\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0065 - val_accuracy: 0.9991 - val_loss: 1.0025\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0042 - val_accuracy: 0.9991 - val_loss: 1.0090\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0036 - val_accuracy: 0.9991 - val_loss: 1.0170\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0042 - val_accuracy: 0.9991 - val_loss: 1.0273\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0033 - val_accuracy: 0.9991 - val_loss: 1.0343\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9993 - loss: 0.0081 - val_accuracy: 0.9974 - val_loss: 1.3119\n",
            "Testing configuration 12/12: layers=[256, 128, 64], learning_rate=0.01, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9870 - loss: 0.0455 - val_accuracy: 0.9992 - val_loss: 0.0857\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9988 - loss: 0.0142 - val_accuracy: 0.9992 - val_loss: 0.1647\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0048 - val_accuracy: 0.9992 - val_loss: 0.1543\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 8.7646e-04 - val_accuracy: 0.9988 - val_loss: 0.3294\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0076 - val_accuracy: 0.9992 - val_loss: 0.3101\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0106 - val_accuracy: 0.9992 - val_loss: 0.0876\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9995 - loss: 0.0040 - val_accuracy: 0.9992 - val_loss: 0.1310\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0035 - val_accuracy: 0.9992 - val_loss: 0.1453\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0041 - val_accuracy: 0.9992 - val_loss: 0.1451\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0036 - val_accuracy: 0.9992 - val_loss: 0.1453\n",
            "Best parameters for deobfuscated: {'layers': [128, 64], 'learning_rate': 0.01, 'epochs': 10, 'batch_size': 32}\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9912 - loss: 0.0303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:839: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
            "    score = scorer._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_response.py\", line 182, in _get_response_values\n",
            "    classes = estimator.classes_\n",
            "AttributeError: 'KerasClassifierWrapper' object has no attribute 'classes_'\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9863 - loss: 0.0438\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9906 - loss: 0.0442\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0363\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9904 - loss: 0.0453\n",
            "Cross-validation accuracy for deobfuscated: nan (+/- nan)\n",
            "Training model on deobfuscated data...\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9891 - loss: 0.0593 - val_accuracy: 0.9975 - val_loss: 0.0131\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0118 - val_accuracy: 0.9892 - val_loss: 0.0510\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9984 - loss: 0.0225 - val_accuracy: 0.9993 - val_loss: 0.0052\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0032 - val_accuracy: 0.9996 - val_loss: 9.7233e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0017 - val_accuracy: 0.9999 - val_loss: 4.0052e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 2.7001e-04 - val_accuracy: 0.9999 - val_loss: 2.5617e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 5.8771e-04 - val_accuracy: 1.0000 - val_loss: 5.9714e-05\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 1.8352e-04 - val_accuracy: 1.0000 - val_loss: 3.3549e-05\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 6.4066e-04 - val_accuracy: 0.9996 - val_loss: 0.0021\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0024 - val_accuracy: 0.9993 - val_loss: 0.0017\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 4.2938e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/model_none_deobfuscated.keras\n",
            "Metrics saved to /content/metrics_none_deobfuscated.txt\n",
            "\n",
            "Processing obfuscation level: low\n",
            "Preprocessing data with obfuscation level: low\n",
            "Optimizing hyperparameters for obfuscated data...\n",
            "Testing configuration 1/12: layers=[64, 32], learning_rate=0.001, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9510 - loss: 0.1412 - val_accuracy: 0.9992 - val_loss: 0.0138\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0053 - val_accuracy: 0.9992 - val_loss: 0.0155\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0046 - val_accuracy: 0.9992 - val_loss: 0.0149\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0051 - val_accuracy: 0.9992 - val_loss: 0.0143\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0038 - val_accuracy: 0.9992 - val_loss: 0.0109\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0037 - val_accuracy: 0.9992 - val_loss: 0.0059\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0032 - val_accuracy: 0.9992 - val_loss: 0.0181\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0025 - val_accuracy: 0.9992 - val_loss: 0.0154\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 7.8566e-04 - val_accuracy: 0.9992 - val_loss: 0.0131\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 8.7908e-04 - val_accuracy: 0.9992 - val_loss: 0.0150\n",
            "Testing configuration 2/12: layers=[64, 32], learning_rate=0.001, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9240 - loss: 0.2309 - val_accuracy: 0.9992 - val_loss: 0.0071\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0083 - val_accuracy: 0.9992 - val_loss: 0.0261\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0056 - val_accuracy: 0.9992 - val_loss: 0.0269\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0050 - val_accuracy: 0.9992 - val_loss: 0.0282\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0074 - val_accuracy: 0.9992 - val_loss: 0.0291\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0043 - val_accuracy: 0.9992 - val_loss: 0.0305\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0048 - val_accuracy: 0.9992 - val_loss: 0.0319\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0051 - val_accuracy: 0.9992 - val_loss: 0.0337\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0034 - val_accuracy: 0.9992 - val_loss: 0.0345\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0024 - val_accuracy: 0.9992 - val_loss: 0.0357\n",
            "Testing configuration 3/12: layers=[64, 32], learning_rate=0.01, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9847 - loss: 0.0411 - val_accuracy: 0.9992 - val_loss: 0.0601\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0064 - val_accuracy: 0.9992 - val_loss: 0.0611\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9987 - loss: 0.0098 - val_accuracy: 0.9992 - val_loss: 0.0242\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0036 - val_accuracy: 0.9992 - val_loss: 0.0660\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0035 - val_accuracy: 0.9992 - val_loss: 0.0747\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0015 - val_accuracy: 0.9992 - val_loss: 0.0607\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 7.6134e-04 - val_accuracy: 0.9995 - val_loss: 0.0627\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 4.2894e-04 - val_accuracy: 0.9998 - val_loss: 0.0595\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3443e-04 - val_accuracy: 0.9998 - val_loss: 0.0528\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 5.7872e-04 - val_accuracy: 0.9996 - val_loss: 0.0409\n",
            "Testing configuration 4/12: layers=[64, 32], learning_rate=0.01, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9797 - loss: 0.0589 - val_accuracy: 0.9991 - val_loss: 0.1159\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0061 - val_accuracy: 0.9992 - val_loss: 0.1391\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0052 - val_accuracy: 0.9992 - val_loss: 0.1583\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0032 - val_accuracy: 0.9992 - val_loss: 0.1917\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0024 - val_accuracy: 0.9992 - val_loss: 0.1755\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 4.5611e-04 - val_accuracy: 0.9995 - val_loss: 0.1881\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 2.9517e-04 - val_accuracy: 0.9998 - val_loss: 0.1906\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.3810e-04 - val_accuracy: 0.9998 - val_loss: 0.1883\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7287e-04 - val_accuracy: 0.9998 - val_loss: 0.1854\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5403e-04 - val_accuracy: 0.9998 - val_loss: 0.1857\n",
            "Testing configuration 5/12: layers=[128, 64], learning_rate=0.001, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9590 - loss: 0.1114 - val_accuracy: 0.9992 - val_loss: 0.0212\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0049 - val_accuracy: 0.9992 - val_loss: 0.0217\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0072 - val_accuracy: 0.9992 - val_loss: 0.0241\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0041 - val_accuracy: 0.9992 - val_loss: 0.0243\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0040 - val_accuracy: 0.9992 - val_loss: 0.0244\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0018 - val_accuracy: 0.9992 - val_loss: 0.0261\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0013 - val_accuracy: 0.9997 - val_loss: 0.0228\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 4.4858e-04 - val_accuracy: 0.9998 - val_loss: 0.0257\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 6.1802e-04 - val_accuracy: 0.9997 - val_loss: 0.0249\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5319e-05 - val_accuracy: 0.9998 - val_loss: 0.0252\n",
            "Testing configuration 6/12: layers=[128, 64], learning_rate=0.001, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9478 - loss: 0.1481 - val_accuracy: 0.9992 - val_loss: 0.0157\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0075 - val_accuracy: 0.9992 - val_loss: 0.0178\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0067 - val_accuracy: 0.9992 - val_loss: 0.0192\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0051 - val_accuracy: 0.9992 - val_loss: 0.0225\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0054 - val_accuracy: 0.9992 - val_loss: 0.0226\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0021 - val_accuracy: 0.9992 - val_loss: 0.0270\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0032 - val_accuracy: 0.9992 - val_loss: 0.0254\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0025 - val_accuracy: 0.9992 - val_loss: 0.0219\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.9992 - val_loss: 0.0179\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0010 - val_accuracy: 0.9996 - val_loss: 0.0158\n",
            "Testing configuration 7/12: layers=[128, 64], learning_rate=0.01, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9919 - loss: 0.0313 - val_accuracy: 0.9992 - val_loss: 0.1682\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0056 - val_accuracy: 0.9992 - val_loss: 0.1986\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0109 - val_accuracy: 0.9992 - val_loss: 0.2235\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0036 - val_accuracy: 0.9992 - val_loss: 0.2094\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0016 - val_accuracy: 0.9992 - val_loss: 0.1824\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0064 - val_accuracy: 0.9992 - val_loss: 0.1594\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0015 - val_accuracy: 0.9992 - val_loss: 0.1909\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 9.5487e-04 - val_accuracy: 0.9992 - val_loss: 0.2770\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0024 - val_accuracy: 0.9992 - val_loss: 0.2326\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0018 - val_accuracy: 0.9992 - val_loss: 0.1775\n",
            "Testing configuration 8/12: layers=[128, 64], learning_rate=0.01, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9912 - loss: 0.0382 - val_accuracy: 0.9992 - val_loss: 0.0952\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0056 - val_accuracy: 0.9992 - val_loss: 0.0964\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0032 - val_accuracy: 0.9992 - val_loss: 0.0944\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9986 - loss: 0.0104 - val_accuracy: 0.9992 - val_loss: 0.0090\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0071 - val_accuracy: 0.9991 - val_loss: 0.0197\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0081 - val_accuracy: 0.9992 - val_loss: 0.0210\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.9986 - val_loss: 1.3601\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0054 - val_accuracy: 0.9992 - val_loss: 1.1042\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 8.7502e-04 - val_accuracy: 0.9992 - val_loss: 1.1030\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 4.0520e-04 - val_accuracy: 0.9997 - val_loss: 1.1028\n",
            "Testing configuration 9/12: layers=[256, 128, 64], learning_rate=0.001, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9827 - loss: 0.0674 - val_accuracy: 0.9992 - val_loss: 0.0244\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0061 - val_accuracy: 0.9992 - val_loss: 0.0245\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0045 - val_accuracy: 0.9992 - val_loss: 0.0140\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0047 - val_accuracy: 0.9992 - val_loss: 0.0038\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0025 - val_accuracy: 0.9996 - val_loss: 0.0121\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 6.4613e-04 - val_accuracy: 0.9998 - val_loss: 0.0058\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2603e-04 - val_accuracy: 0.9998 - val_loss: 0.0034\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 2.5536e-04 - val_accuracy: 0.9998 - val_loss: 0.0016\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 4.5728e-04 - val_accuracy: 0.9998 - val_loss: 0.1962\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0600e-05 - val_accuracy: 0.9998 - val_loss: 0.1948\n",
            "Testing configuration 10/12: layers=[256, 128, 64], learning_rate=0.001, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9641 - loss: 0.0979 - val_accuracy: 0.9993 - val_loss: 0.0075\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9992 - loss: 0.0062 - val_accuracy: 0.9992 - val_loss: 0.1175\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0047 - val_accuracy: 0.9992 - val_loss: 0.1243\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0037 - val_accuracy: 0.9992 - val_loss: 0.1279\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 0.9996 - val_loss: 0.1376\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.3020e-04 - val_accuracy: 0.9996 - val_loss: 0.1435\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 2.3268e-04 - val_accuracy: 0.9998 - val_loss: 0.1529\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.4085e-05 - val_accuracy: 0.9998 - val_loss: 0.1532\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.3412e-05 - val_accuracy: 0.9998 - val_loss: 0.1532\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.7831e-05 - val_accuracy: 0.9998 - val_loss: 0.1568\n",
            "Testing configuration 11/12: layers=[256, 128, 64], learning_rate=0.01, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9920 - loss: 0.0512 - val_accuracy: 0.9992 - val_loss: 0.2677\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0091 - val_accuracy: 0.9991 - val_loss: 0.5963\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0258 - val_accuracy: 0.9991 - val_loss: 0.7612\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0034 - val_accuracy: 0.9991 - val_loss: 0.9644\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0040 - val_accuracy: 0.9991 - val_loss: 1.1886\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0157 - val_accuracy: 0.9991 - val_loss: 1.0779\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0051 - val_accuracy: 0.9989 - val_loss: 1.3203\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0032 - val_accuracy: 0.9992 - val_loss: 1.1540\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0041 - val_accuracy: 0.9992 - val_loss: 0.9895\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0036 - val_accuracy: 0.9992 - val_loss: 1.1409\n",
            "Testing configuration 12/12: layers=[256, 128, 64], learning_rate=0.01, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9882 - loss: 0.0446 - val_accuracy: 0.9991 - val_loss: 0.4122\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0103 - val_accuracy: 0.9992 - val_loss: 0.2024\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0073 - val_accuracy: 0.9992 - val_loss: 0.3551\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0095 - val_accuracy: 0.9991 - val_loss: 0.0361\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9992 - loss: 0.0054 - val_accuracy: 0.9991 - val_loss: 0.0904\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9995 - loss: 0.0076 - val_accuracy: 0.9991 - val_loss: 0.2320\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0036 - val_accuracy: 0.9992 - val_loss: 0.0956\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0033 - val_accuracy: 0.9992 - val_loss: 0.0794\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9995 - loss: 0.0053 - val_accuracy: 0.9992 - val_loss: 0.0436\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0034 - val_accuracy: 0.9992 - val_loss: 0.0413\n",
            "Best parameters for obfuscated: {'layers': [64, 32], 'learning_rate': 0.01, 'epochs': 10, 'batch_size': 64}\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9883 - loss: 0.0428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:839: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
            "    score = scorer._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_response.py\", line 182, in _get_response_values\n",
            "    classes = estimator.classes_\n",
            "AttributeError: 'KerasClassifierWrapper' object has no attribute 'classes_'\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9848 - loss: 0.0406\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9868 - loss: 0.0434\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9881 - loss: 0.0417\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9884 - loss: 0.0430\n",
            "Cross-validation accuracy for obfuscated: nan (+/- nan)\n",
            "Training model on obfuscated data...\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9722 - loss: 0.0726 - val_accuracy: 0.9935 - val_loss: 0.0211\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0283 - val_accuracy: 0.9993 - val_loss: 0.0056\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0042 - val_accuracy: 0.9993 - val_loss: 0.0030\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0031 - val_accuracy: 0.9993 - val_loss: 0.0043\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.9993 - val_loss: 9.2543e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0012 - val_accuracy: 0.9993 - val_loss: 6.3567e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 5.6211e-04 - val_accuracy: 0.9999 - val_loss: 4.5955e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0012 - val_accuracy: 0.9999 - val_loss: 3.7245e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2970e-04 - val_accuracy: 1.0000 - val_loss: 2.5860e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 3.6314e-04 - val_accuracy: 1.0000 - val_loss: 4.7876e-04\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.4857e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/model_low_obfuscated.keras\n",
            "Metrics saved to /content/metrics_low_obfuscated.txt\n",
            "Optimizing hyperparameters for deobfuscated data...\n",
            "Testing configuration 1/12: layers=[64, 32], learning_rate=0.001, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9638 - loss: 0.1493 - val_accuracy: 0.9992 - val_loss: 0.0147\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0040 - val_accuracy: 0.9992 - val_loss: 0.0155\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0062 - val_accuracy: 0.9992 - val_loss: 0.0162\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0043 - val_accuracy: 0.9992 - val_loss: 0.0165\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0044 - val_accuracy: 0.9992 - val_loss: 0.0161\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0033 - val_accuracy: 0.9992 - val_loss: 0.0162\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0028 - val_accuracy: 0.9992 - val_loss: 0.0157\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0013 - val_accuracy: 0.9992 - val_loss: 0.0143\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 7.2173e-04 - val_accuracy: 0.9996 - val_loss: 0.0128\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 4.2574e-04 - val_accuracy: 0.9997 - val_loss: 0.0162\n",
            "Testing configuration 2/12: layers=[64, 32], learning_rate=0.001, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9368 - loss: 0.2146 - val_accuracy: 0.9992 - val_loss: 0.0093\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0048 - val_accuracy: 0.9992 - val_loss: 0.0086\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0084 - val_accuracy: 0.9992 - val_loss: 0.0343\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0052 - val_accuracy: 0.9992 - val_loss: 0.0350\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0049 - val_accuracy: 0.9992 - val_loss: 0.0349\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0071 - val_accuracy: 0.9992 - val_loss: 0.0349\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0048 - val_accuracy: 0.9992 - val_loss: 0.0351\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0039 - val_accuracy: 0.9992 - val_loss: 0.0341\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0027 - val_accuracy: 0.9992 - val_loss: 0.0360\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0038 - val_accuracy: 0.9992 - val_loss: 0.0367\n",
            "Testing configuration 3/12: layers=[64, 32], learning_rate=0.01, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9875 - loss: 0.0357 - val_accuracy: 0.9991 - val_loss: 0.0450\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9977 - loss: 0.0141 - val_accuracy: 0.9991 - val_loss: 0.1630\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0065 - val_accuracy: 0.9992 - val_loss: 0.1560\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0047 - val_accuracy: 0.9992 - val_loss: 0.1183\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0029 - val_accuracy: 0.9992 - val_loss: 0.1577\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.9992 - val_loss: 0.0988\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 8.2797e-04 - val_accuracy: 0.9992 - val_loss: 0.0743\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 4.5812e-04 - val_accuracy: 0.9996 - val_loss: 0.0800\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0025 - val_accuracy: 0.9991 - val_loss: 0.0854\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0018 - val_accuracy: 0.9995 - val_loss: 0.0657\n",
            "Testing configuration 4/12: layers=[64, 32], learning_rate=0.01, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9788 - loss: 0.0603 - val_accuracy: 0.9992 - val_loss: 0.0854\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0048 - val_accuracy: 0.9991 - val_loss: 0.1012\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0063 - val_accuracy: 0.9992 - val_loss: 0.1110\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0025 - val_accuracy: 0.9992 - val_loss: 0.0870\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0010 - val_accuracy: 0.9992 - val_loss: 0.0745\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0024 - val_accuracy: 0.9992 - val_loss: 0.0840\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 4.4621e-04 - val_accuracy: 0.9993 - val_loss: 0.0778\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0025 - val_accuracy: 0.9998 - val_loss: 0.0628\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 7.7871e-04 - val_accuracy: 0.9996 - val_loss: 0.0798\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.2430e-04 - val_accuracy: 0.9998 - val_loss: 0.0761\n",
            "Testing configuration 5/12: layers=[128, 64], learning_rate=0.001, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9674 - loss: 0.1123 - val_accuracy: 0.9992 - val_loss: 0.0247\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0044 - val_accuracy: 0.9992 - val_loss: 0.0274\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0047 - val_accuracy: 0.9992 - val_loss: 0.0287\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0038 - val_accuracy: 0.9992 - val_loss: 0.0314\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0025 - val_accuracy: 0.9992 - val_loss: 0.0341\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0013 - val_accuracy: 0.9992 - val_loss: 0.0374\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 5.5480e-04 - val_accuracy: 0.9996 - val_loss: 0.0373\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0024 - val_accuracy: 0.9996 - val_loss: 0.0429\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 3.9738e-04 - val_accuracy: 0.9996 - val_loss: 0.0377\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7434e-04 - val_accuracy: 0.9996 - val_loss: 0.0384\n",
            "Testing configuration 6/12: layers=[128, 64], learning_rate=0.001, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9572 - loss: 0.1538 - val_accuracy: 0.9992 - val_loss: 0.0077\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0048 - val_accuracy: 0.9992 - val_loss: 0.0073\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0027 - val_accuracy: 0.9992 - val_loss: 0.0087\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0054 - val_accuracy: 0.9992 - val_loss: 0.0088\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0026 - val_accuracy: 0.9992 - val_loss: 0.0097\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0031 - val_accuracy: 0.9992 - val_loss: 0.0083\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0032 - val_accuracy: 0.9992 - val_loss: 0.0090\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0040 - val_accuracy: 0.9992 - val_loss: 0.0077\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0021 - val_accuracy: 0.9992 - val_loss: 0.0077\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0019 - val_accuracy: 0.9992 - val_loss: 0.0075\n",
            "Testing configuration 7/12: layers=[128, 64], learning_rate=0.01, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9907 - loss: 0.0320 - val_accuracy: 0.9992 - val_loss: 0.1464\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0060 - val_accuracy: 0.9992 - val_loss: 0.1068\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0084 - val_accuracy: 0.9992 - val_loss: 0.1492\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0053 - val_accuracy: 0.9992 - val_loss: 0.1233\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0019 - val_accuracy: 0.9992 - val_loss: 0.1483\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0022 - val_accuracy: 0.9998 - val_loss: 0.1334\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.9996 - val_loss: 0.0113\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 0.9998 - val_loss: 0.0156\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0014 - val_accuracy: 0.9998 - val_loss: 2.0973e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0022 - val_accuracy: 0.9992 - val_loss: 0.5649\n",
            "Testing configuration 8/12: layers=[128, 64], learning_rate=0.01, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9890 - loss: 0.0504 - val_accuracy: 0.9992 - val_loss: 0.0538\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0074 - val_accuracy: 0.9992 - val_loss: 0.0573\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0031 - val_accuracy: 0.9992 - val_loss: 0.0623\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 7.5159e-04 - val_accuracy: 0.9995 - val_loss: 0.0482\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 6.0383e-04 - val_accuracy: 0.9998 - val_loss: 0.0492\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0092 - val_accuracy: 0.9998 - val_loss: 0.0163\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 2.5860e-04 - val_accuracy: 0.9998 - val_loss: 0.0101\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.3806e-06 - val_accuracy: 0.9998 - val_loss: 0.0138\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 2.0395e-04 - val_accuracy: 0.9998 - val_loss: 0.0220\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0036 - val_accuracy: 0.9998 - val_loss: 0.0344\n",
            "Testing configuration 9/12: layers=[256, 128, 64], learning_rate=0.001, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9717 - loss: 0.0717 - val_accuracy: 0.9991 - val_loss: 0.0182\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0058 - val_accuracy: 0.9992 - val_loss: 0.1023\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0023 - val_accuracy: 0.9992 - val_loss: 0.1228\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0012 - val_accuracy: 0.9992 - val_loss: 0.1841\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 7.3703e-04 - val_accuracy: 0.9998 - val_loss: 0.2028\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.3373e-04 - val_accuracy: 0.9998 - val_loss: 0.2042\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 1.8017e-04 - val_accuracy: 0.9998 - val_loss: 0.2422\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.1876e-05 - val_accuracy: 0.9992 - val_loss: 0.2694\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 8.4031e-04 - val_accuracy: 0.9998 - val_loss: 0.2243\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0019 - val_accuracy: 0.9998 - val_loss: 0.2445\n",
            "Testing configuration 10/12: layers=[256, 128, 64], learning_rate=0.001, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9613 - loss: 0.1027 - val_accuracy: 0.9992 - val_loss: 0.0334\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0042 - val_accuracy: 0.9992 - val_loss: 0.0347\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9994 - loss: 0.0050 - val_accuracy: 0.9992 - val_loss: 0.0234\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9989 - loss: 0.0059 - val_accuracy: 0.9992 - val_loss: 0.0321\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0019 - val_accuracy: 0.9992 - val_loss: 0.0338\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 5.9760e-04 - val_accuracy: 0.9992 - val_loss: 0.0262\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9997 - loss: 3.8027e-04 - val_accuracy: 0.9998 - val_loss: 0.0269\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.1315e-04 - val_accuracy: 0.9998 - val_loss: 0.0277\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.7003e-05 - val_accuracy: 0.9998 - val_loss: 0.0252\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.9410e-05 - val_accuracy: 0.9998 - val_loss: 0.0143\n",
            "Testing configuration 11/12: layers=[256, 128, 64], learning_rate=0.01, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9914 - loss: 0.0497 - val_accuracy: 0.9992 - val_loss: 0.2210\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0186 - val_accuracy: 0.9992 - val_loss: 0.8627\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9991 - loss: 0.0074 - val_accuracy: 0.9992 - val_loss: 0.7439\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0036 - val_accuracy: 0.9992 - val_loss: 0.7457\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0046 - val_accuracy: 0.9992 - val_loss: 0.7483\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0046 - val_accuracy: 0.9992 - val_loss: 0.8112\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0044 - val_accuracy: 0.9991 - val_loss: 0.9245\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0039 - val_accuracy: 0.9991 - val_loss: 0.9244\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0043 - val_accuracy: 0.9991 - val_loss: 1.0196\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0043 - val_accuracy: 0.9991 - val_loss: 1.0205\n",
            "Testing configuration 12/12: layers=[256, 128, 64], learning_rate=0.01, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9884 - loss: 0.0441 - val_accuracy: 0.9991 - val_loss: 0.5006\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9991 - loss: 0.0092 - val_accuracy: 0.9992 - val_loss: 0.2900\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0065 - val_accuracy: 0.9992 - val_loss: 0.1468\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0102 - val_accuracy: 0.9991 - val_loss: 0.9355\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0047 - val_accuracy: 0.9991 - val_loss: 0.9516\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0037 - val_accuracy: 0.9992 - val_loss: 0.8971\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9980 - loss: 0.0221 - val_accuracy: 0.9991 - val_loss: 0.5980\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0046 - val_accuracy: 0.9991 - val_loss: 0.5805\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0046 - val_accuracy: 0.9992 - val_loss: 0.5601\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0032 - val_accuracy: 0.9992 - val_loss: 0.5335\n",
            "Best parameters for deobfuscated: {'layers': [64, 32], 'learning_rate': 0.01, 'epochs': 10, 'batch_size': 64}\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9861 - loss: 0.0419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:839: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
            "    score = scorer._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_response.py\", line 182, in _get_response_values\n",
            "    classes = estimator.classes_\n",
            "AttributeError: 'KerasClassifierWrapper' object has no attribute 'classes_'\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9879 - loss: 0.0446\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9847 - loss: 0.0507\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9842 - loss: 0.0469\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9923 - loss: 0.0364\n",
            "Cross-validation accuracy for deobfuscated: nan (+/- nan)\n",
            "Training model on deobfuscated data...\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9755 - loss: 0.0614 - val_accuracy: 0.9993 - val_loss: 0.0063\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0063 - val_accuracy: 0.9993 - val_loss: 0.0070\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0046 - val_accuracy: 0.9993 - val_loss: 0.0030\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0046 - val_accuracy: 0.9993 - val_loss: 8.1010e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0018 - val_accuracy: 0.9993 - val_loss: 0.0011\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0017 - val_accuracy: 0.9993 - val_loss: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0011 - val_accuracy: 0.9993 - val_loss: 0.0018\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 9.8671e-04 - val_accuracy: 1.0000 - val_loss: 3.9527e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5962e-04 - val_accuracy: 0.9993 - val_loss: 0.0015\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0057 - val_accuracy: 1.0000 - val_loss: 2.1824e-04\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.3481e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/model_low_deobfuscated.keras\n",
            "Metrics saved to /content/metrics_low_deobfuscated.txt\n",
            "\n",
            "Processing obfuscation level: medium\n",
            "Preprocessing data with obfuscation level: medium\n",
            "Optimizing hyperparameters for obfuscated data...\n",
            "Testing configuration 1/12: layers=[64, 32], learning_rate=0.001, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9511 - loss: 0.1510 - val_accuracy: 0.9992 - val_loss: 0.0080\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0070 - val_accuracy: 0.9995 - val_loss: 0.0056\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0058 - val_accuracy: 0.9992 - val_loss: 0.0268\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0067 - val_accuracy: 0.9992 - val_loss: 0.0283\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0039 - val_accuracy: 0.9992 - val_loss: 0.0297\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0039 - val_accuracy: 0.9992 - val_loss: 0.0331\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0027 - val_accuracy: 0.9992 - val_loss: 0.0326\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0021 - val_accuracy: 0.9992 - val_loss: 0.0370\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 7.5475e-04 - val_accuracy: 0.9992 - val_loss: 0.0404\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 5.5219e-04 - val_accuracy: 0.9996 - val_loss: 0.0451\n",
            "Testing configuration 2/12: layers=[64, 32], learning_rate=0.001, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9261 - loss: 0.2262 - val_accuracy: 0.9992 - val_loss: 0.0172\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0074 - val_accuracy: 0.9992 - val_loss: 0.0173\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0064 - val_accuracy: 0.9992 - val_loss: 0.0178\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0057 - val_accuracy: 0.9992 - val_loss: 0.0184\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0052 - val_accuracy: 0.9992 - val_loss: 0.0191\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0044 - val_accuracy: 0.9992 - val_loss: 0.0196\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0046 - val_accuracy: 0.9992 - val_loss: 0.0214\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0036 - val_accuracy: 0.9992 - val_loss: 0.0223\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0039 - val_accuracy: 0.9992 - val_loss: 0.0220\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0041 - val_accuracy: 0.9992 - val_loss: 0.0241\n",
            "Testing configuration 3/12: layers=[64, 32], learning_rate=0.01, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9896 - loss: 0.0320 - val_accuracy: 0.9991 - val_loss: 0.1743\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0059 - val_accuracy: 0.9992 - val_loss: 0.1659\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0047 - val_accuracy: 0.9992 - val_loss: 0.1538\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0054 - val_accuracy: 0.9992 - val_loss: 0.1310\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0035 - val_accuracy: 0.9992 - val_loss: 0.1362\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.9992 - val_loss: 0.1082\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.9992 - val_loss: 0.0978\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 8.8806e-04 - val_accuracy: 0.9992 - val_loss: 0.0934\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0022 - val_accuracy: 0.9992 - val_loss: 0.0367\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 5.5876e-04 - val_accuracy: 0.9992 - val_loss: 0.0254\n",
            "Testing configuration 4/12: layers=[64, 32], learning_rate=0.01, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9830 - loss: 0.0554 - val_accuracy: 0.9992 - val_loss: 0.0911\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0054 - val_accuracy: 0.9992 - val_loss: 0.0966\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0026 - val_accuracy: 0.9992 - val_loss: 0.1088\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0043 - val_accuracy: 0.9991 - val_loss: 0.1515\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0017 - val_accuracy: 0.9992 - val_loss: 0.1650\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 7.2766e-04 - val_accuracy: 0.9992 - val_loss: 0.1680\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 3.7861e-04 - val_accuracy: 0.9998 - val_loss: 0.1624\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4110e-04 - val_accuracy: 0.9998 - val_loss: 0.1613\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0040 - val_accuracy: 0.9992 - val_loss: 0.2194\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0040 - val_accuracy: 0.9996 - val_loss: 0.2176\n",
            "Testing configuration 5/12: layers=[128, 64], learning_rate=0.001, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9786 - loss: 0.0970 - val_accuracy: 0.9992 - val_loss: 0.0223\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0049 - val_accuracy: 0.9992 - val_loss: 0.0238\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0052 - val_accuracy: 0.9992 - val_loss: 0.0249\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0028 - val_accuracy: 0.9992 - val_loss: 0.0244\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0034 - val_accuracy: 0.9992 - val_loss: 0.0254\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0036 - val_accuracy: 0.9992 - val_loss: 0.0270\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0013 - val_accuracy: 0.9992 - val_loss: 0.0270\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 6.3376e-04 - val_accuracy: 0.9996 - val_loss: 0.0306\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 3.0340e-04 - val_accuracy: 0.9996 - val_loss: 0.0309\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 3.8004e-04 - val_accuracy: 0.9998 - val_loss: 0.0279\n",
            "Testing configuration 6/12: layers=[128, 64], learning_rate=0.001, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9621 - loss: 0.1512 - val_accuracy: 0.9992 - val_loss: 0.0124\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0058 - val_accuracy: 0.9992 - val_loss: 0.0116\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0056 - val_accuracy: 0.9992 - val_loss: 0.0117\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0038 - val_accuracy: 0.9992 - val_loss: 0.0108\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0049 - val_accuracy: 0.9992 - val_loss: 0.0122\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0034 - val_accuracy: 0.9992 - val_loss: 0.0115\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0035 - val_accuracy: 0.9992 - val_loss: 0.0108\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0043 - val_accuracy: 0.9992 - val_loss: 0.0074\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0021 - val_accuracy: 0.9992 - val_loss: 0.0039\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0012 - val_accuracy: 0.9995 - val_loss: 9.4628e-04\n",
            "Testing configuration 7/12: layers=[128, 64], learning_rate=0.01, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0261 - val_accuracy: 0.9991 - val_loss: 0.2689\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0048 - val_accuracy: 0.9991 - val_loss: 0.2648\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0075 - val_accuracy: 0.9992 - val_loss: 0.1839\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0039 - val_accuracy: 0.9992 - val_loss: 0.1893\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0039 - val_accuracy: 0.9992 - val_loss: 0.1850\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0016 - val_accuracy: 0.9989 - val_loss: 0.2119\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0067 - val_accuracy: 0.9992 - val_loss: 0.2128\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0036 - val_accuracy: 0.9992 - val_loss: 0.1755\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0042 - val_accuracy: 0.9992 - val_loss: 0.4851\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0040 - val_accuracy: 0.9992 - val_loss: 0.4206\n",
            "Testing configuration 8/12: layers=[128, 64], learning_rate=0.01, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9899 - loss: 0.0367 - val_accuracy: 0.9992 - val_loss: 0.0548\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0054 - val_accuracy: 0.9992 - val_loss: 0.0240\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0037 - val_accuracy: 0.9992 - val_loss: 0.0328\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0012 - val_accuracy: 0.9989 - val_loss: 1.0429\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0071 - val_accuracy: 0.9992 - val_loss: 0.9675\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.9992 - val_loss: 0.9140\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 7.7470e-04 - val_accuracy: 0.9992 - val_loss: 0.9121\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 4.7106e-04 - val_accuracy: 0.9992 - val_loss: 0.9730\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0029 - val_accuracy: 0.9992 - val_loss: 1.0056\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 8.7977e-04 - val_accuracy: 0.9996 - val_loss: 0.9679\n",
            "Testing configuration 9/12: layers=[256, 128, 64], learning_rate=0.001, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9753 - loss: 0.0683 - val_accuracy: 0.9992 - val_loss: 0.1057\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0044 - val_accuracy: 0.9940 - val_loss: 0.1571\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0060 - val_accuracy: 0.9992 - val_loss: 0.1210\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0031 - val_accuracy: 0.9992 - val_loss: 0.1247\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.9992 - val_loss: 0.1160\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0013 - val_accuracy: 0.9996 - val_loss: 0.1083\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.5376e-04 - val_accuracy: 0.9998 - val_loss: 0.1096\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.1744e-04 - val_accuracy: 0.9998 - val_loss: 0.1123\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 2.1286e-04 - val_accuracy: 0.9996 - val_loss: 0.1014\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0010 - val_accuracy: 0.9998 - val_loss: 0.0774\n",
            "Testing configuration 10/12: layers=[256, 128, 64], learning_rate=0.001, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9703 - loss: 0.0877 - val_accuracy: 0.9992 - val_loss: 0.0840\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9995 - loss: 0.0047 - val_accuracy: 0.9992 - val_loss: 0.0886\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9994 - loss: 0.0052 - val_accuracy: 0.9992 - val_loss: 0.0904\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0028 - val_accuracy: 0.9992 - val_loss: 0.0992\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9993 - loss: 0.0029 - val_accuracy: 0.9992 - val_loss: 0.1069\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 9.2295e-04 - val_accuracy: 0.9995 - val_loss: 0.1232\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 5.0955e-04 - val_accuracy: 0.9998 - val_loss: 0.1430\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 8.3394e-05 - val_accuracy: 0.9998 - val_loss: 0.1442\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 6.1338e-05 - val_accuracy: 0.9998 - val_loss: 0.1532\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.7003e-04 - val_accuracy: 0.9998 - val_loss: 0.1437\n",
            "Testing configuration 11/12: layers=[256, 128, 64], learning_rate=0.01, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9879 - loss: 0.0599 - val_accuracy: 0.9991 - val_loss: 0.1946\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0085 - val_accuracy: 0.9991 - val_loss: 0.2659\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0117 - val_accuracy: 0.9991 - val_loss: 0.3517\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9986 - loss: 0.0140 - val_accuracy: 0.9991 - val_loss: 0.0521\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0037 - val_accuracy: 0.9991 - val_loss: 0.0861\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0038 - val_accuracy: 0.9992 - val_loss: 0.0193\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0041 - val_accuracy: 0.9992 - val_loss: 0.0203\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0032 - val_accuracy: 0.9992 - val_loss: 0.0183\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0035 - val_accuracy: 0.9992 - val_loss: 0.0192\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9994 - loss: 0.0045 - val_accuracy: 0.9992 - val_loss: 0.0184\n",
            "Testing configuration 12/12: layers=[256, 128, 64], learning_rate=0.01, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9874 - loss: 0.0465 - val_accuracy: 0.9991 - val_loss: 0.4254\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0057 - val_accuracy: 0.9991 - val_loss: 0.4203\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0079 - val_accuracy: 0.9991 - val_loss: 0.3364\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0065 - val_accuracy: 0.9992 - val_loss: 0.9268\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0106 - val_accuracy: 0.9992 - val_loss: 0.3369\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0048 - val_accuracy: 0.9992 - val_loss: 0.4140\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0064 - val_accuracy: 0.9992 - val_loss: 0.4737\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0035 - val_accuracy: 0.9992 - val_loss: 0.4478\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9995 - loss: 0.0039 - val_accuracy: 0.9992 - val_loss: 0.3693\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0033 - val_accuracy: 0.9992 - val_loss: 0.2780\n",
            "Best parameters for obfuscated: {'layers': [128, 64], 'learning_rate': 0.001, 'epochs': 10, 'batch_size': 32}\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9798 - loss: 0.0972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:839: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
            "    score = scorer._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_response.py\", line 182, in _get_response_values\n",
            "    classes = estimator.classes_\n",
            "AttributeError: 'KerasClassifierWrapper' object has no attribute 'classes_'\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9587 - loss: 0.1175\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9686 - loss: 0.1012\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9780 - loss: 0.1000\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9804 - loss: 0.0969\n",
            "Cross-validation accuracy for obfuscated: nan (+/- nan)\n",
            "Training model on obfuscated data...\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9621 - loss: 0.1236 - val_accuracy: 0.9993 - val_loss: 0.0072\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0060 - val_accuracy: 0.9993 - val_loss: 0.0063\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0083 - val_accuracy: 0.9993 - val_loss: 0.0056\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0038 - val_accuracy: 0.9993 - val_loss: 0.0048\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0060 - val_accuracy: 0.9993 - val_loss: 0.0037\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0018 - val_accuracy: 0.9993 - val_loss: 0.0016\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0016 - val_accuracy: 0.9993 - val_loss: 8.2937e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0011 - val_accuracy: 0.9996 - val_loss: 9.4566e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 4.8802e-04 - val_accuracy: 0.9997 - val_loss: 6.8452e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 4.4426e-04 - val_accuracy: 0.9999 - val_loss: 6.1507e-04\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.4867e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/model_medium_obfuscated.keras\n",
            "Metrics saved to /content/metrics_medium_obfuscated.txt\n",
            "Optimizing hyperparameters for deobfuscated data...\n",
            "Testing configuration 1/12: layers=[64, 32], learning_rate=0.001, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9620 - loss: 0.1421 - val_accuracy: 0.9992 - val_loss: 0.0172\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0054 - val_accuracy: 0.9992 - val_loss: 0.0189\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0046 - val_accuracy: 0.9992 - val_loss: 0.0212\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0046 - val_accuracy: 0.9992 - val_loss: 0.0215\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0050 - val_accuracy: 0.9992 - val_loss: 0.0223\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0023 - val_accuracy: 0.9992 - val_loss: 0.0231\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0043 - val_accuracy: 0.9992 - val_loss: 0.0270\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0019 - val_accuracy: 0.9992 - val_loss: 0.0274\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0013 - val_accuracy: 0.9992 - val_loss: 0.0269\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 6.3445e-04 - val_accuracy: 0.9996 - val_loss: 0.0307\n",
            "Testing configuration 2/12: layers=[64, 32], learning_rate=0.001, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2448 - val_accuracy: 0.9992 - val_loss: 0.0150\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0069 - val_accuracy: 0.9992 - val_loss: 0.0173\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0076 - val_accuracy: 0.9992 - val_loss: 0.0189\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0055 - val_accuracy: 0.9992 - val_loss: 0.0208\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0043 - val_accuracy: 0.9992 - val_loss: 0.0210\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0045 - val_accuracy: 0.9992 - val_loss: 0.0224\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0047 - val_accuracy: 0.9992 - val_loss: 0.0247\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0027 - val_accuracy: 0.9992 - val_loss: 0.0252\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0035 - val_accuracy: 0.9992 - val_loss: 0.0280\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0040 - val_accuracy: 0.9992 - val_loss: 0.0307\n",
            "Testing configuration 3/12: layers=[64, 32], learning_rate=0.01, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9855 - loss: 0.0368 - val_accuracy: 0.9992 - val_loss: 0.1128\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0040 - val_accuracy: 0.9992 - val_loss: 0.1221\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0039 - val_accuracy: 0.9992 - val_loss: 0.1477\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0019 - val_accuracy: 0.9996 - val_loss: 0.0931\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0064 - val_accuracy: 0.9992 - val_loss: 0.1056\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0024 - val_accuracy: 0.9992 - val_loss: 0.0547\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0025 - val_accuracy: 0.9992 - val_loss: 0.9477\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 7.2445e-04 - val_accuracy: 0.9993 - val_loss: 0.9369\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 9.8489e-04 - val_accuracy: 0.9995 - val_loss: 0.9702\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0019 - val_accuracy: 0.9997 - val_loss: 0.8502\n",
            "Testing configuration 4/12: layers=[64, 32], learning_rate=0.01, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9804 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0483\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0048 - val_accuracy: 0.9992 - val_loss: 0.0401\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0043 - val_accuracy: 0.9992 - val_loss: 0.0274\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0044 - val_accuracy: 0.9991 - val_loss: 0.0169\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0023 - val_accuracy: 0.9992 - val_loss: 0.0254\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0015 - val_accuracy: 0.9992 - val_loss: 0.0189\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 4.7747e-04 - val_accuracy: 0.9992 - val_loss: 0.0190\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 5.6537e-04 - val_accuracy: 0.9997 - val_loss: 0.0152\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1957e-04 - val_accuracy: 0.9998 - val_loss: 0.0154\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.9558e-04 - val_accuracy: 0.9996 - val_loss: 0.0040\n",
            "Testing configuration 5/12: layers=[128, 64], learning_rate=0.001, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9702 - loss: 0.1090 - val_accuracy: 0.9992 - val_loss: 0.0154\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0028 - val_accuracy: 0.9992 - val_loss: 0.0181\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0052 - val_accuracy: 0.9992 - val_loss: 0.0201\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0039 - val_accuracy: 0.9992 - val_loss: 0.0207\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0054 - val_accuracy: 0.9992 - val_loss: 0.0210\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0029 - val_accuracy: 0.9992 - val_loss: 0.0183\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 9.6774e-04 - val_accuracy: 0.9995 - val_loss: 0.0287\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 3.8970e-04 - val_accuracy: 0.9996 - val_loss: 0.0162\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9953e-04 - val_accuracy: 0.9997 - val_loss: 0.0251\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0023 - val_accuracy: 0.9998 - val_loss: 0.0274\n",
            "Testing configuration 6/12: layers=[128, 64], learning_rate=0.001, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9545 - loss: 0.1582 - val_accuracy: 0.9992 - val_loss: 0.0166\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0041 - val_accuracy: 0.9992 - val_loss: 0.0176\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0059 - val_accuracy: 0.9992 - val_loss: 0.0185\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0044 - val_accuracy: 0.9992 - val_loss: 0.0200\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0038 - val_accuracy: 0.9992 - val_loss: 0.0201\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0020 - val_accuracy: 0.9992 - val_loss: 0.0219\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0044 - val_accuracy: 0.9992 - val_loss: 0.0210\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0037 - val_accuracy: 0.9992 - val_loss: 0.0193\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.9992 - val_loss: 0.0198\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0011 - val_accuracy: 0.9992 - val_loss: 0.0171\n",
            "Testing configuration 7/12: layers=[128, 64], learning_rate=0.01, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9877 - loss: 0.0369 - val_accuracy: 0.9992 - val_loss: 0.0896\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0066 - val_accuracy: 0.9992 - val_loss: 0.0835\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0030 - val_accuracy: 0.9992 - val_loss: 0.1726\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0062 - val_accuracy: 0.9992 - val_loss: 0.2773\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0026 - val_accuracy: 0.9987 - val_loss: 0.3286\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0051 - val_accuracy: 0.9992 - val_loss: 0.2522\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0062 - val_accuracy: 0.9992 - val_loss: 0.1112\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0014 - val_accuracy: 0.9992 - val_loss: 0.1499\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0073 - val_accuracy: 0.9992 - val_loss: 0.1416\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0028 - val_accuracy: 0.9992 - val_loss: 0.1151\n",
            "Testing configuration 8/12: layers=[128, 64], learning_rate=0.01, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9863 - loss: 0.0359 - val_accuracy: 0.9992 - val_loss: 0.0201\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0072 - val_accuracy: 0.9992 - val_loss: 0.1087\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0050 - val_accuracy: 0.9992 - val_loss: 0.0989\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0016 - val_accuracy: 0.9991 - val_loss: 0.1587\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0039 - val_accuracy: 0.9991 - val_loss: 0.0925\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0086 - val_accuracy: 0.9992 - val_loss: 0.0487\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0020 - val_accuracy: 0.9992 - val_loss: 0.0299\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 3.5774e-04 - val_accuracy: 0.9996 - val_loss: 0.0306\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.7282e-04 - val_accuracy: 0.9998 - val_loss: 0.0282\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.3900e-04 - val_accuracy: 0.9976 - val_loss: 0.0643\n",
            "Testing configuration 9/12: layers=[256, 128, 64], learning_rate=0.001, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9837 - loss: 0.0583 - val_accuracy: 0.9992 - val_loss: 0.1016\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0050 - val_accuracy: 0.9992 - val_loss: 0.1136\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0052 - val_accuracy: 0.9992 - val_loss: 0.1370\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0031 - val_accuracy: 0.9992 - val_loss: 0.1596\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0015 - val_accuracy: 0.9996 - val_loss: 0.1924\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0060 - val_accuracy: 0.9998 - val_loss: 0.1634\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.0347e-05 - val_accuracy: 0.9998 - val_loss: 0.1652\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.1416e-05 - val_accuracy: 0.9998 - val_loss: 0.1666\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.4739e-05 - val_accuracy: 0.9992 - val_loss: 0.1670\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0019 - val_accuracy: 0.9998 - val_loss: 0.1577\n",
            "Testing configuration 10/12: layers=[256, 128, 64], learning_rate=0.001, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9707 - loss: 0.0958 - val_accuracy: 0.9992 - val_loss: 0.0388\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0050 - val_accuracy: 0.9992 - val_loss: 0.0433\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0038 - val_accuracy: 0.9992 - val_loss: 0.0640\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0020 - val_accuracy: 0.9992 - val_loss: 0.0581\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 9.9801e-04 - val_accuracy: 0.9992 - val_loss: 0.0614\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0010 - val_accuracy: 0.9998 - val_loss: 0.0501\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 2.7090e-04 - val_accuracy: 0.9998 - val_loss: 0.0488\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.6313e-04 - val_accuracy: 0.9996 - val_loss: 0.0070\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9998 - loss: 5.1983e-04 - val_accuracy: 0.9999 - val_loss: 0.0044\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0044 - val_accuracy: 0.9998 - val_loss: 0.1809\n",
            "Testing configuration 11/12: layers=[256, 128, 64], learning_rate=0.01, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9891 - loss: 0.0403 - val_accuracy: 0.9992 - val_loss: 0.6790\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9988 - loss: 0.0208 - val_accuracy: 0.9992 - val_loss: 1.1756\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0074 - val_accuracy: 0.9992 - val_loss: 0.7725\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0048 - val_accuracy: 0.9991 - val_loss: 0.6053\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9992 - loss: 0.0076 - val_accuracy: 0.9992 - val_loss: 0.6060\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0040 - val_accuracy: 0.9992 - val_loss: 0.6043\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0033 - val_accuracy: 0.9992 - val_loss: 0.6075\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0108 - val_accuracy: 0.9990 - val_loss: 1.5555\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0095 - val_accuracy: 0.9992 - val_loss: 1.7612\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9994 - loss: 0.0042 - val_accuracy: 0.9992 - val_loss: 2.0922\n",
            "Testing configuration 12/12: layers=[256, 128, 64], learning_rate=0.01, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9841 - loss: 0.0517 - val_accuracy: 0.9992 - val_loss: 0.0212\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9992 - loss: 0.0101 - val_accuracy: 0.9991 - val_loss: 0.0828\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0062 - val_accuracy: 0.9992 - val_loss: 0.4044\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0034 - val_accuracy: 0.9992 - val_loss: 0.4068\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9995 - loss: 0.0044 - val_accuracy: 0.9992 - val_loss: 0.3678\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9995 - loss: 0.0039 - val_accuracy: 0.9992 - val_loss: 0.4004\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9995 - loss: 0.0039 - val_accuracy: 0.9992 - val_loss: 0.4247\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9994 - loss: 0.0048 - val_accuracy: 0.9992 - val_loss: 0.4546\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9995 - loss: 0.0036 - val_accuracy: 0.9992 - val_loss: 0.4524\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9995 - loss: 0.0035 - val_accuracy: 0.9992 - val_loss: 0.4542\n",
            "Best parameters for deobfuscated: {'layers': [128, 64], 'learning_rate': 0.001, 'epochs': 10, 'batch_size': 32}\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9691 - loss: 0.0993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:839: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
            "    score = scorer._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_response.py\", line 182, in _get_response_values\n",
            "    classes = estimator.classes_\n",
            "AttributeError: 'KerasClassifierWrapper' object has no attribute 'classes_'\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9605 - loss: 0.1115\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9768 - loss: 0.0994\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9753 - loss: 0.0981\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9538 - loss: 0.1192\n",
            "Cross-validation accuracy for deobfuscated: nan (+/- nan)\n",
            "Training model on deobfuscated data...\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9763 - loss: 0.1038 - val_accuracy: 0.9993 - val_loss: 0.0069\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0054 - val_accuracy: 0.9993 - val_loss: 0.0066\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0093 - val_accuracy: 0.9993 - val_loss: 0.0054\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0034 - val_accuracy: 0.9993 - val_loss: 0.0045\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0038 - val_accuracy: 0.9993 - val_loss: 0.0034\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0025 - val_accuracy: 0.9993 - val_loss: 0.0019\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0023 - val_accuracy: 0.9993 - val_loss: 0.0013\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 7.5389e-04 - val_accuracy: 0.9993 - val_loss: 8.3483e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 8.4796e-04 - val_accuracy: 0.9998 - val_loss: 6.6366e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.2939e-04 - val_accuracy: 0.9998 - val_loss: 6.0667e-04\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.4327e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/model_medium_deobfuscated.keras\n",
            "Metrics saved to /content/metrics_medium_deobfuscated.txt\n",
            "\n",
            "Processing obfuscation level: high\n",
            "Preprocessing data with obfuscation level: high\n",
            "Optimizing hyperparameters for obfuscated data...\n",
            "Testing configuration 1/12: layers=[64, 32], learning_rate=0.001, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9458 - loss: 0.1638 - val_accuracy: 0.9992 - val_loss: 0.0149\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0064 - val_accuracy: 0.9992 - val_loss: 0.0157\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0078 - val_accuracy: 0.9992 - val_loss: 0.0171\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0050 - val_accuracy: 0.9992 - val_loss: 0.0173\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0049 - val_accuracy: 0.9992 - val_loss: 0.0177\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0039 - val_accuracy: 0.9992 - val_loss: 0.0160\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0028 - val_accuracy: 0.9992 - val_loss: 0.0156\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.9992 - val_loss: 0.0144\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 8.9365e-04 - val_accuracy: 0.9993 - val_loss: 0.0116\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 4.6091e-04 - val_accuracy: 0.9996 - val_loss: 0.0091\n",
            "Testing configuration 2/12: layers=[64, 32], learning_rate=0.001, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9475 - loss: 0.2229 - val_accuracy: 0.9992 - val_loss: 0.0126\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0059 - val_accuracy: 0.9992 - val_loss: 0.0122\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0046 - val_accuracy: 0.9992 - val_loss: 0.0123\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0063 - val_accuracy: 0.9992 - val_loss: 0.0119\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0077 - val_accuracy: 0.9992 - val_loss: 0.0125\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0047 - val_accuracy: 0.9992 - val_loss: 0.0129\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0047 - val_accuracy: 0.9992 - val_loss: 0.0135\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0045 - val_accuracy: 0.9992 - val_loss: 0.0148\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0041 - val_accuracy: 0.9992 - val_loss: 0.0149\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0028 - val_accuracy: 0.9992 - val_loss: 0.0164\n",
            "Testing configuration 3/12: layers=[64, 32], learning_rate=0.01, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9853 - loss: 0.0420 - val_accuracy: 0.9991 - val_loss: 0.0447\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0062 - val_accuracy: 0.9992 - val_loss: 0.0321\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0052 - val_accuracy: 0.9992 - val_loss: 0.0223\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0023 - val_accuracy: 0.9992 - val_loss: 0.0061\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 8.1886e-04 - val_accuracy: 0.9968 - val_loss: 0.0531\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9978 - loss: 0.0149 - val_accuracy: 0.9992 - val_loss: 0.3453\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0019 - val_accuracy: 0.9992 - val_loss: 0.3668\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0034 - val_accuracy: 0.9992 - val_loss: 0.3660\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 8.7034e-04 - val_accuracy: 0.9992 - val_loss: 0.3697\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 3.0432e-04 - val_accuracy: 0.9998 - val_loss: 0.3501\n",
            "Testing configuration 4/12: layers=[64, 32], learning_rate=0.01, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9791 - loss: 0.0565 - val_accuracy: 0.9992 - val_loss: 0.0402\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0042 - val_accuracy: 0.9992 - val_loss: 0.0422\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0043 - val_accuracy: 0.9992 - val_loss: 0.0419\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0062 - val_accuracy: 0.9992 - val_loss: 0.0082\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0022 - val_accuracy: 0.9992 - val_loss: 0.0037\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 9.4716e-04 - val_accuracy: 0.9992 - val_loss: 0.0160\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 7.8146e-04 - val_accuracy: 0.9997 - val_loss: 0.0167\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 3.8447e-04 - val_accuracy: 0.9992 - val_loss: 0.0181\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 4.7637e-04 - val_accuracy: 0.9998 - val_loss: 0.0141\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 2.6824e-04 - val_accuracy: 0.9998 - val_loss: 0.0140\n",
            "Testing configuration 5/12: layers=[128, 64], learning_rate=0.001, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9760 - loss: 0.0992 - val_accuracy: 0.9992 - val_loss: 0.0192\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0052 - val_accuracy: 0.9992 - val_loss: 0.0194\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0049 - val_accuracy: 0.9992 - val_loss: 0.0207\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0041 - val_accuracy: 0.9992 - val_loss: 0.0209\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0037 - val_accuracy: 0.9992 - val_loss: 0.0217\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.9992 - val_loss: 0.0226\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 5.1900e-04 - val_accuracy: 0.9995 - val_loss: 0.0248\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 2.5876e-04 - val_accuracy: 0.9996 - val_loss: 0.0258\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7346e-04 - val_accuracy: 0.9997 - val_loss: 0.0238\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.4895e-04 - val_accuracy: 0.9998 - val_loss: 0.0217\n",
            "Testing configuration 6/12: layers=[128, 64], learning_rate=0.001, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.1343 - val_accuracy: 0.9992 - val_loss: 0.0196\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0035 - val_accuracy: 0.9992 - val_loss: 0.0207\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0052 - val_accuracy: 0.9992 - val_loss: 0.0219\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0054 - val_accuracy: 0.9992 - val_loss: 0.0231\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0049 - val_accuracy: 0.9992 - val_loss: 0.0229\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0035 - val_accuracy: 0.9992 - val_loss: 0.0243\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0033 - val_accuracy: 0.9992 - val_loss: 0.0248\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0021 - val_accuracy: 0.9992 - val_loss: 0.0259\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.9992 - val_loss: 0.0291\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0010 - val_accuracy: 0.9992 - val_loss: 0.0259\n",
            "Testing configuration 7/12: layers=[128, 64], learning_rate=0.01, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9882 - loss: 0.0371 - val_accuracy: 0.9992 - val_loss: 0.0942\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0077 - val_accuracy: 0.9992 - val_loss: 0.0505\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0052 - val_accuracy: 0.9992 - val_loss: 0.0846\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0023 - val_accuracy: 0.9998 - val_loss: 0.1188\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0033 - val_accuracy: 0.9992 - val_loss: 0.0308\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0123 - val_accuracy: 0.9992 - val_loss: 0.1924\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0022 - val_accuracy: 0.9992 - val_loss: 0.1613\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0022 - val_accuracy: 0.9992 - val_loss: 0.2081\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0019 - val_accuracy: 0.9992 - val_loss: 0.1894\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0075 - val_accuracy: 0.9992 - val_loss: 0.1637\n",
            "Testing configuration 8/12: layers=[128, 64], learning_rate=0.01, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9840 - loss: 0.0434 - val_accuracy: 0.9992 - val_loss: 0.1502\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0061 - val_accuracy: 0.9992 - val_loss: 0.1640\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0074 - val_accuracy: 0.9991 - val_loss: 0.1751\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0057 - val_accuracy: 0.9991 - val_loss: 0.1612\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0046 - val_accuracy: 0.9992 - val_loss: 0.1962\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0015 - val_accuracy: 0.9992 - val_loss: 0.1747\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 5.6369e-04 - val_accuracy: 0.9992 - val_loss: 0.1720\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 3.9104e-04 - val_accuracy: 0.9996 - val_loss: 0.1648\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 3.5204e-04 - val_accuracy: 0.9998 - val_loss: 0.1583\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3906e-04 - val_accuracy: 0.9997 - val_loss: 0.1563\n",
            "Testing configuration 9/12: layers=[256, 128, 64], learning_rate=0.001, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9728 - loss: 0.0685 - val_accuracy: 0.9991 - val_loss: 0.0969\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0069 - val_accuracy: 0.9992 - val_loss: 0.1112\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0036 - val_accuracy: 0.9992 - val_loss: 0.1224\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0036 - val_accuracy: 0.9992 - val_loss: 0.1281\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0024 - val_accuracy: 0.9993 - val_loss: 0.1338\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 5.5418e-04 - val_accuracy: 0.9998 - val_loss: 0.1606\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.3039e-04 - val_accuracy: 0.9998 - val_loss: 0.1613\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.4175e-04 - val_accuracy: 0.9992 - val_loss: 0.1970\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 3.8272e-04 - val_accuracy: 0.9997 - val_loss: 0.2196\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.0206e-05 - val_accuracy: 0.9998 - val_loss: 0.2197\n",
            "Testing configuration 10/12: layers=[256, 128, 64], learning_rate=0.001, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9639 - loss: 0.0999 - val_accuracy: 0.9992 - val_loss: 0.0578\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0033 - val_accuracy: 0.9992 - val_loss: 0.0596\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0047 - val_accuracy: 0.9992 - val_loss: 0.0614\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0032 - val_accuracy: 0.9992 - val_loss: 0.0587\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.9993 - val_loss: 0.0561\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 3.7553e-04 - val_accuracy: 0.9997 - val_loss: 0.0573\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 2.5035e-04 - val_accuracy: 0.9998 - val_loss: 0.0553\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.7716e-05 - val_accuracy: 0.9998 - val_loss: 0.0596\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.3539e-05 - val_accuracy: 0.9998 - val_loss: 0.0605\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.6884e-06 - val_accuracy: 0.9998 - val_loss: 0.0596\n",
            "Testing configuration 11/12: layers=[256, 128, 64], learning_rate=0.01, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9877 - loss: 0.0434 - val_accuracy: 0.9991 - val_loss: 0.4729\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0087 - val_accuracy: 0.9991 - val_loss: 0.7274\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0096 - val_accuracy: 0.9992 - val_loss: 1.5672\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0122 - val_accuracy: 0.9991 - val_loss: 0.6637\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0050 - val_accuracy: 0.9991 - val_loss: 0.6994\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0050 - val_accuracy: 0.9991 - val_loss: 3.1369\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0035 - val_accuracy: 0.9992 - val_loss: 3.2262\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0047 - val_accuracy: 0.9992 - val_loss: 3.2348\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0029 - val_accuracy: 0.9992 - val_loss: 3.2349\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0056 - val_accuracy: 0.9992 - val_loss: 0.9050\n",
            "Testing configuration 12/12: layers=[256, 128, 64], learning_rate=0.01, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9847 - loss: 0.0465 - val_accuracy: 0.9991 - val_loss: 0.2089\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0072 - val_accuracy: 0.9992 - val_loss: 0.2112\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0062 - val_accuracy: 0.9992 - val_loss: 0.2453\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0018 - val_accuracy: 0.9992 - val_loss: 0.3363\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9991 - loss: 0.0031 - val_accuracy: 0.9992 - val_loss: 0.4505\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0052 - val_accuracy: 0.9992 - val_loss: 0.3375\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0035 - val_accuracy: 0.9992 - val_loss: 0.2299\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0031 - val_accuracy: 0.9992 - val_loss: 0.1978\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9997 - loss: 6.4172e-04 - val_accuracy: 0.9998 - val_loss: 0.2126\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0024 - val_accuracy: 0.9992 - val_loss: 0.2178\n",
            "Best parameters for obfuscated: {'layers': [64, 32], 'learning_rate': 0.01, 'epochs': 10, 'batch_size': 32}\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9887 - loss: 0.0408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:839: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
            "    score = scorer._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_response.py\", line 182, in _get_response_values\n",
            "    classes = estimator.classes_\n",
            "AttributeError: 'KerasClassifierWrapper' object has no attribute 'classes_'\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9876 - loss: 0.0414\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9867 - loss: 0.0467\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0404\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9831 - loss: 0.0595\n",
            "Cross-validation accuracy for obfuscated: nan (+/- nan)\n",
            "Training model on obfuscated data...\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9882 - loss: 0.0421 - val_accuracy: 0.9993 - val_loss: 0.0060\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0032 - val_accuracy: 0.9992 - val_loss: 0.0051\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0049 - val_accuracy: 0.9993 - val_loss: 0.0046\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0023 - val_accuracy: 0.9993 - val_loss: 0.0015\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0065 - val_accuracy: 0.9993 - val_loss: 0.0014\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0011 - val_accuracy: 0.9993 - val_loss: 9.8194e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 9.2647e-04 - val_accuracy: 0.9998 - val_loss: 4.7303e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 0.9993 - val_loss: 0.0044\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 3.0002e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 3.7393e-04 - val_accuracy: 0.9999 - val_loss: 2.5149e-04\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2299e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/model_high_obfuscated.keras\n",
            "Metrics saved to /content/metrics_high_obfuscated.txt\n",
            "Optimizing hyperparameters for deobfuscated data...\n",
            "Testing configuration 1/12: layers=[64, 32], learning_rate=0.001, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9500 - loss: 0.1467 - val_accuracy: 0.9992 - val_loss: 0.0106\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0052 - val_accuracy: 0.9992 - val_loss: 0.0109\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0053 - val_accuracy: 0.9992 - val_loss: 0.0121\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0037 - val_accuracy: 0.9992 - val_loss: 0.0126\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0054 - val_accuracy: 0.9992 - val_loss: 0.0134\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0043 - val_accuracy: 0.9992 - val_loss: 0.0120\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0044 - val_accuracy: 0.9992 - val_loss: 0.0102\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0024 - val_accuracy: 0.9992 - val_loss: 0.0114\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0013 - val_accuracy: 0.9992 - val_loss: 0.0105\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 6.4385e-04 - val_accuracy: 0.9992 - val_loss: 0.0125\n",
            "Testing configuration 2/12: layers=[64, 32], learning_rate=0.001, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9272 - loss: 0.2214 - val_accuracy: 0.9992 - val_loss: 0.0148\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0049 - val_accuracy: 0.9992 - val_loss: 0.0158\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0059 - val_accuracy: 0.9992 - val_loss: 0.0163\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0054 - val_accuracy: 0.9992 - val_loss: 0.0171\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0059 - val_accuracy: 0.9992 - val_loss: 0.0173\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0047 - val_accuracy: 0.9992 - val_loss: 0.0176\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0046 - val_accuracy: 0.9992 - val_loss: 0.0178\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0043 - val_accuracy: 0.9992 - val_loss: 0.0185\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0030 - val_accuracy: 0.9992 - val_loss: 0.0190\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0035 - val_accuracy: 0.9992 - val_loss: 0.0167\n",
            "Testing configuration 3/12: layers=[64, 32], learning_rate=0.01, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9895 - loss: 0.0405 - val_accuracy: 0.9991 - val_loss: 0.0247\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0066 - val_accuracy: 0.9992 - val_loss: 0.0092\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0043 - val_accuracy: 0.9992 - val_loss: 0.0218\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0032 - val_accuracy: 0.9992 - val_loss: 0.0161\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0023 - val_accuracy: 0.9992 - val_loss: 0.0115\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 5.0004e-04 - val_accuracy: 0.9992 - val_loss: 0.0121\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.0102 - val_accuracy: 0.9992 - val_loss: 0.0962\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0016 - val_accuracy: 0.9992 - val_loss: 0.0659\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 4.3845e-04 - val_accuracy: 0.9998 - val_loss: 0.0699\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.9312e-04 - val_accuracy: 0.9998 - val_loss: 0.0694\n",
            "Testing configuration 4/12: layers=[64, 32], learning_rate=0.01, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9763 - loss: 0.0588 - val_accuracy: 0.9992 - val_loss: 0.0142\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0078 - val_accuracy: 0.9992 - val_loss: 0.1050\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0042 - val_accuracy: 0.9992 - val_loss: 0.1232\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0058 - val_accuracy: 0.9992 - val_loss: 0.1833\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 8.1869e-04 - val_accuracy: 0.9992 - val_loss: 0.1896\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 5.5010e-04 - val_accuracy: 0.9997 - val_loss: 0.1925\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 3.6310e-04 - val_accuracy: 0.9992 - val_loss: 0.1975\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0038 - val_accuracy: 0.9992 - val_loss: 0.1878\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0042 - val_accuracy: 0.9992 - val_loss: 0.1953\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0016 - val_accuracy: 0.9996 - val_loss: 0.2424\n",
            "Testing configuration 5/12: layers=[128, 64], learning_rate=0.001, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9714 - loss: 0.1013 - val_accuracy: 0.9992 - val_loss: 0.0226\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0045 - val_accuracy: 0.9992 - val_loss: 0.0239\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0047 - val_accuracy: 0.9992 - val_loss: 0.0249\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0037 - val_accuracy: 0.9992 - val_loss: 0.0271\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0026 - val_accuracy: 0.9992 - val_loss: 0.0269\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0023 - val_accuracy: 0.9992 - val_loss: 0.0273\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0016 - val_accuracy: 0.9992 - val_loss: 0.0258\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 7.5291e-04 - val_accuracy: 0.9995 - val_loss: 0.0270\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 5.0879e-04 - val_accuracy: 0.9996 - val_loss: 0.0284\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 4.1676e-04 - val_accuracy: 0.9998 - val_loss: 0.0279\n",
            "Testing configuration 6/12: layers=[128, 64], learning_rate=0.001, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9500 - loss: 0.1581 - val_accuracy: 0.9992 - val_loss: 0.0193\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0049 - val_accuracy: 0.9992 - val_loss: 0.0199\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0057 - val_accuracy: 0.9992 - val_loss: 0.0209\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0040 - val_accuracy: 0.9992 - val_loss: 0.0209\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0049 - val_accuracy: 0.9992 - val_loss: 0.0213\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0047 - val_accuracy: 0.9992 - val_loss: 0.0214\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0030 - val_accuracy: 0.9992 - val_loss: 0.0218\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0027 - val_accuracy: 0.9992 - val_loss: 0.0167\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0010 - val_accuracy: 0.9996 - val_loss: 0.0156\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 3.6422e-04 - val_accuracy: 0.9998 - val_loss: 0.0152\n",
            "Testing configuration 7/12: layers=[128, 64], learning_rate=0.01, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9904 - loss: 0.0336 - val_accuracy: 0.9992 - val_loss: 0.1969\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0044 - val_accuracy: 0.9992 - val_loss: 0.1348\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0040 - val_accuracy: 0.9991 - val_loss: 0.1592\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0038 - val_accuracy: 0.9992 - val_loss: 0.1036\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0042 - val_accuracy: 0.9992 - val_loss: 0.1482\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0026 - val_accuracy: 0.9992 - val_loss: 0.0754\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0011 - val_accuracy: 0.9992 - val_loss: 0.0317\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 5.9198e-04 - val_accuracy: 0.9998 - val_loss: 0.0149\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0124 - val_accuracy: 0.9992 - val_loss: 0.0621\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0013 - val_accuracy: 0.9990 - val_loss: 0.0262\n",
            "Testing configuration 8/12: layers=[128, 64], learning_rate=0.01, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9825 - loss: 0.0456 - val_accuracy: 0.9992 - val_loss: 0.2161\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0051 - val_accuracy: 0.9992 - val_loss: 0.2348\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0060 - val_accuracy: 0.9992 - val_loss: 0.2097\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0023 - val_accuracy: 0.9992 - val_loss: 0.2004\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0016 - val_accuracy: 0.9992 - val_loss: 0.2151\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 5.3453e-04 - val_accuracy: 0.9992 - val_loss: 0.2155\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0011 - val_accuracy: 0.9990 - val_loss: 0.3069\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0029 - val_accuracy: 0.9992 - val_loss: 0.2086\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 4.9736e-04 - val_accuracy: 0.9996 - val_loss: 0.1952\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5362e-04 - val_accuracy: 0.9998 - val_loss: 0.1942\n",
            "Testing configuration 9/12: layers=[256, 128, 64], learning_rate=0.001, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9838 - loss: 0.0647 - val_accuracy: 0.9992 - val_loss: 0.0200\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0045 - val_accuracy: 0.9992 - val_loss: 0.0061\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0069 - val_accuracy: 0.9992 - val_loss: 0.1121\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0019 - val_accuracy: 0.9992 - val_loss: 0.1258\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 4.2557e-04 - val_accuracy: 0.9998 - val_loss: 0.1259\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 8.5751e-04 - val_accuracy: 0.9996 - val_loss: 0.1510\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.7225e-04 - val_accuracy: 0.9998 - val_loss: 0.1489\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 0.9997 - val_loss: 0.1302\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 1.2948e-04 - val_accuracy: 0.9998 - val_loss: 0.1211\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 1.1490e-04 - val_accuracy: 0.9998 - val_loss: 0.1200\n",
            "Testing configuration 10/12: layers=[256, 128, 64], learning_rate=0.001, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9731 - loss: 0.0840 - val_accuracy: 0.9992 - val_loss: 0.0192\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0062 - val_accuracy: 0.9993 - val_loss: 0.0068\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0065 - val_accuracy: 0.9992 - val_loss: 0.1445\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9995 - loss: 0.0040 - val_accuracy: 0.9992 - val_loss: 0.1459\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0037 - val_accuracy: 0.9992 - val_loss: 0.1596\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9978 - loss: 0.0102 - val_accuracy: 0.9992 - val_loss: 0.1409\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 5.6733e-04 - val_accuracy: 0.9998 - val_loss: 0.1472\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.6627e-04 - val_accuracy: 0.9998 - val_loss: 0.1370\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9998 - loss: 6.6607e-04 - val_accuracy: 0.9998 - val_loss: 0.1667\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.9685e-05 - val_accuracy: 0.9998 - val_loss: 0.1663\n",
            "Testing configuration 11/12: layers=[256, 128, 64], learning_rate=0.01, epochs=10, batch_size=32\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9926 - loss: 0.0421 - val_accuracy: 0.9991 - val_loss: 1.1463\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0079 - val_accuracy: 0.9992 - val_loss: 1.0154\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0212 - val_accuracy: 0.9991 - val_loss: 1.7148\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0058 - val_accuracy: 0.9992 - val_loss: 1.2250\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0087 - val_accuracy: 0.9992 - val_loss: 2.3426\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0027 - val_accuracy: 0.9992 - val_loss: 2.1884\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0036 - val_accuracy: 0.9992 - val_loss: 2.1774\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0032 - val_accuracy: 0.9992 - val_loss: 2.2828\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0053 - val_accuracy: 0.9992 - val_loss: 2.2695\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0189 - val_accuracy: 0.9992 - val_loss: 3.2630\n",
            "Testing configuration 12/12: layers=[256, 128, 64], learning_rate=0.01, epochs=10, batch_size=64\n",
            "Epoch 1/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9871 - loss: 0.0427 - val_accuracy: 0.9993 - val_loss: 0.0095\n",
            "Epoch 2/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9987 - loss: 0.0150 - val_accuracy: 0.9991 - val_loss: 1.3826\n",
            "Epoch 3/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0059 - val_accuracy: 0.9992 - val_loss: 1.3930\n",
            "Epoch 4/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0039 - val_accuracy: 0.9992 - val_loss: 1.2933\n",
            "Epoch 5/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0024 - val_accuracy: 0.9992 - val_loss: 1.2728\n",
            "Epoch 6/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0148 - val_accuracy: 0.9990 - val_loss: 0.5013\n",
            "Epoch 7/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9989 - loss: 0.0067 - val_accuracy: 0.9992 - val_loss: 0.9281\n",
            "Epoch 8/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0039 - val_accuracy: 0.9992 - val_loss: 0.8873\n",
            "Epoch 9/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0037 - val_accuracy: 0.9992 - val_loss: 0.8942\n",
            "Epoch 10/10\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0032 - val_accuracy: 0.9992 - val_loss: 0.8914\n",
            "Best parameters for deobfuscated: {'layers': [64, 32], 'learning_rate': 0.01, 'epochs': 10, 'batch_size': 32}\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9836 - loss: 0.0482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:839: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
            "    score = scorer._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_response.py\", line 182, in _get_response_values\n",
            "    classes = estimator.classes_\n",
            "AttributeError: 'KerasClassifierWrapper' object has no attribute 'classes_'\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9901 - loss: 0.0360\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0489\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9837 - loss: 0.0567\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9890 - loss: 0.0437\n",
            "Cross-validation accuracy for deobfuscated: nan (+/- nan)\n",
            "Training model on deobfuscated data...\n",
            "Epoch 1/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9915 - loss: 0.0389 - val_accuracy: 0.9993 - val_loss: 0.0097\n",
            "Epoch 2/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0063 - val_accuracy: 0.9993 - val_loss: 0.0049\n",
            "Epoch 3/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0031 - val_accuracy: 0.9993 - val_loss: 8.4956e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0039 - val_accuracy: 0.9993 - val_loss: 0.0017\n",
            "Epoch 5/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0017 - val_accuracy: 0.9993 - val_loss: 6.0737e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 4.8937e-04 - val_accuracy: 0.9999 - val_loss: 3.9976e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 5.6697e-04 - val_accuracy: 0.9993 - val_loss: 0.0034\n",
            "Epoch 8/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0018 - val_accuracy: 0.9995 - val_loss: 5.5717e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 3.1395e-04 - val_accuracy: 1.0000 - val_loss: 1.9353e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 3.0794e-04 - val_accuracy: 1.0000 - val_loss: 1.4442e-04\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.0093e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/model_high_deobfuscated.keras\n",
            "Metrics saved to /content/metrics_high_deobfuscated.txt\n",
            "\n",
            "Statistical Significance Test:\n",
            "F-statistic: 1.5881502188669827\n",
            "p-value: 0.25438489745449483\n",
            "Plot saved to /content/performance_plot.png\n",
            "\n",
            "Performance Summary:\n",
            "+-------------------+--------------+----------+---------+-----------+--------+----------+\n",
            "| Obfuscation Level |  Data Type   | Accuracy | ROC AUC | Precision | Recall | F1 Score |\n",
            "+-------------------+--------------+----------+---------+-----------+--------+----------+\n",
            "|        none       |  obfuscated  |  0.9999  |  1.0000 |   0.9997  | 1.0000 |  0.9998  |\n",
            "|        none       | deobfuscated |  0.9995  |  0.9999 |   0.9982  | 1.0000 |  0.9991  |\n",
            "|        low        |  obfuscated  |  0.9999  |  0.9999 |   0.9997  | 1.0000 |  0.9998  |\n",
            "|        low        | deobfuscated |  0.9999  |  0.9999 |   0.9997  | 1.0000 |  0.9998  |\n",
            "|       medium      |  obfuscated  |  0.9999  |  0.9999 |   0.9997  | 1.0000 |  0.9998  |\n",
            "|       medium      | deobfuscated |  0.9998  |  0.9999 |   0.9994  | 1.0000 |  0.9997  |\n",
            "|        high       |  obfuscated  |  0.9999  |  0.9999 |   0.9997  | 1.0000 |  0.9998  |\n",
            "|        high       | deobfuscated |  0.9999  |  0.9999 |   0.9997  | 1.0000 |  0.9998  |\n",
            "+-------------------+--------------+----------+---------+-----------+--------+----------+\n",
            "Summary table saved to /content/summary_table.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results suggest that the model is highly effective and robust, maintaining near-perfect performance across various levels of obfuscation and both types of data.\n",
        "\n",
        "The statistical test reinforces this conclusion, indicating that any minor variations in the metrics are likely due to random chance rather than a true difference in performance.\n",
        "\n",
        "The significance of these results to cybersecurity is that they demonstrate a highly effective model for detecting obfuscated threats, ensuring that security measures remain robust even as attackers employ advanced techniques to hide their malicious activities. This contributes to the overall strengthening of cybersecurity defenses, making systems more resilient against both known and emerging threats."
      ],
      "metadata": {
        "id": "gN36qmP1WWQ_"
      }
    }
  ]
}